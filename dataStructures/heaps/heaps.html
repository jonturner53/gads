<html>
<head>
<title>Heaps</title>
<link type="text/css" rel="stylesheet" href="../../main.css">
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body bgcolor=ffffff>
\(
\newcommand{\key}{\texttt{key}}
\newcommand{\insert}{\texttt{insert}}
\newcommand{\deletemin}{\texttt{deletemin}}
\newcommand{\changekey}{\texttt{changekey}}
\newcommand{\empty}{\texttt{empty}}
\newcommand{\contains}{\texttt{contains}}
\newcommand{\findmin}{\texttt{findmin}}
\newcommand{\delete}{\texttt{delete}}
\newcommand{\addtokeys}{\texttt{add2keys}}
\newcommand{\meld}{\texttt{meld}}
\newcommand{\rank}{\texttt{rank}}
\newcommand{\heapify}{\texttt{heapify}}
\newcommand{\lazyMeld}{\texttt{lazyMeld}}
\newcommand{\retire}{\texttt{retire}}
\newcommand{\Forest}{\texttt{Forest}}
\newcommand{\ArrayHeap}{\texttt{ArrayHeap}}
\newcommand{\FibHeaps}{\texttt{FibHeaps}}
\newcommand{\LeftistHeaps}{\texttt{LeftistHeaps}}
\)

<h1>Heaps<sup>&copy;</sup></h1>

A heap $h$ is an abstract data type that represents
a collection of items, where each item has a numeric <i>key</i>.
A typical heap implementation supports the following methods.
<ul>
<li> $\textit{insert}(i, k)$ inserts item $i$ into the heap with key $k$.
<li> $\textit{deletemin}()$ deletes a minimum key item from the heap and
    returns it.
<li> $\textit{changekey}(i, k)$ changes the key of heap item $i$ to $k$.
</ul>
It is also common to include a <i>findmin</i> method, which returns the item
with the smallest key without deleting it, and a general <i>delete</i> method.
<p>
Efficient heap implementations are usually built around the idea of a
<i>heap-ordered tree</i>,
which is a tree in which each heap item $i$ is viewed as a tree node and
$\textit{key}(i) \geq \textit{key}(p(i))$ where 
$p(i)$ is the parent of $i$ in the tree.
This property ensures that the root of the tree has the
smallest key value.
Using a suitably structured heap-ordered tree, the various operations
can be implemented to run in $O(\log n)$ time.

<a id=arrayHeap><h2>Array Heap</h2></a>
The <i>array heap</i> (also known as $d$-heap) is a simple version
of the heap data type that uses an array to implement a
$d$-ary heap-ordered tree.
The provided <i>Javascript</i> implementation
includes the following methods in addition to the
three standard ones mentioned earlier.
<ul>
<li>    <code>d</code> returns the &ldquo;arity&rdquo; of the heap-ordered tree.
<li>    <code>m</code> returns the number of items in the heap
        (note, this is not the same as the index range).
<li>    $\key(i)$ returns the key of item $i$.
<li>    $\empty()$ returns true if the heap is empty.
<li>    $\contains(i)$ returns true if item $i$ is in the heap.
<li>    $\findmin()$ returns the item with the smallest key.
<li>    $\delete(i)$ deletes item $i$ from the heap.
<li>    $\addtokeys(\Delta)$ adds the value $\Delta$
        to the keys of all heap items.
</ul>
<p>
The web app  can be used to construct a heap from a string and
try out its methods as shown below.
<pre style="padding-left:5%;">
let h = new ArrayHeap(10);
h.fromString('{e:1 f:2 c:5 a:5 d:2 h:7 i:7 j:8 b:6 g:4}');
log(h.toString(1));
let u = h.deletemin();
log(h.index2string(u), h.key(u), ''+h);
</pre>
This produces the output
<pre style="padding-left:5%;">
{e:1(f:2(a:5(j:8 b:6) d:2(g:4)) c:5(h:7 i:7))} 
e 1 {f:2 d:2 a:5 j:8 b:6 g:4 c:5 h:7 i:7} 
</pre>
The first line shows a detailed view of the heap,
before the $\deletemin$ operation.
Parentheses are used to indicate the tree structure.
Specifically, each item with children in the tree is
immediately followed by a parenthesized list of its children.
The final line includes a more concise view of the heap,
just listing all the remaining items and their keys, in some unspecified order.
<p>
The implementation of the array heap stores the $m$ heap items
in positions $1\ldots m$ of an array with the positions of items
determining the relationship between parents and children
in an implicit heap-ordered tree.
This tree has a characteristic <i>heap-shape</i>,
which is illustrated in the example below.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/dheap1.png"><br>
</div>
<p>
The index of an item in the <i>item</i> array is referred to as
its <i>position</i> in the heap,
so in the example, item $b$ is at position 3. The index of a value in the
<i>key</i> array is an item number. Here, they are shown as letters to make it
easier to distinguish the items from the other numeric values.
For a heap item $i$ stored at position $x>1$,
the parent of $i$ is stored at position $\lceil (x-1)/d \rceil$.
Consequently, the children of $i$ (if any) are stored starting at
position $d(x-1)+2$ and continuing consecutively from there.
If $i$ has $d$ children its &ldquo;rightmost&rdquo; is stored at
position $dx+1$.
A third array $pos$ is included to support a general <i>delete</i> method; 
$pos[i]$ gives the position of item $i$ in the <i>item</i> array.
<p>
To insert a new item $u$ into a heap with key $k$, start at the
first unused position in the item array, then go up the tree looking
for the first item with a key that is $\leq k$. The new item
becomes a child of that item and the other items along the path
all move down one level in the tree. So for example, inserting item $l$
with key 5 into the previous example heap yields the following.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/dheap2.png"><br>
</div>
<p>
The insertion is done with the assistance of a helper method
$\textit{siftup}(i, x)$, which scans for a position for item $i$ starting
from position $x$, moving items down as it goes, before inserting $i$
into its final position.
<p>
$\textit{Deletemin}$ is implemented in a similar way.
Let $i$ be the last item in the <i>item</i> array and let
$k = \textit{key}(i)$.
Starting from the root, scan down the heap looking for a
new place to insert $i$. 
At each step, select the
child of the current item that has the smallest key.
When this process reaches an item with a key that is at least as large as $k$,
item $i$ is inserted just above that item, while the other items in
the search path are moved up one level.
So for example, a $\textit{deletemin}$ on the heap
from the last example, yields the configuration shown below.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/dheap3.png"><br>
</div>
<p>
The search process described above is implemented by
a helper method called <i>siftdown</i>.
<p>
The $\addtokeys$ method is implemented by adding an
increment to an internal <i>offset</i>
The key of an item is equal to the sum of the stored key value and the offset.
When an item is inserted into the heap, the key value stored must adjusted to
match the offset.
<p>
The core methods for the $\ArrayHeap$ class are shown below.
<p>
<textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class ArrayHeap extends Top {
    #d;          // base of heap
    #m;          // # of items in the heap set

    #item;       // {#item[1],...,#item[m]} is the items in the heap
    #pos;        // #pos[i] gives position of i in #item
    #key;        // #key[i] is key of item i
    #offset;     // offset for key values, allowing all to shift at once

    constructor(n=10, d=4) {
        super(n);
        this.#item = new Int32Array(n+1);
        this.#pos = new Int32Array(n+1);
        this.#key = new Float32Array(n+1);
        this.#item[0] = this.#m = 0; this.#d = d;
        this.#offset = 0;
    }

    get d() { return this.#d; }

    get m() { return this.#m; }

    itemAt(pos) { return this.#item[pos]; };

    p(pos) { return Math.ceil((pos-1)/this.d); }

    left(pos) { return this.d*(pos-1)+2; }

    right(pos) { return this.d*pos+1; }

    findmin() { return this.empty() ? 0 : this.itemAt(1); }
    
    key(i) { return this.#offset + this.#key[i]; }

    get offset() { return this.#offset; }

    add2keys(delta) { this.#offset += delta; }
    
    contains(i) { return this.#pos[i] != 0; }
    
    empty() { return this.m == 0; };
    
    insert(i, key) {
        if (this.contains(i)) { this.changekey(i,key); return; }
        if (i > this.n) this.expand(i);
        this.#key[i] = key - this.#offset; this.#m++; this.#siftup(i, this.m);
    }
    
    deletemin() {
        if (this.empty()) return 0;
        let i = this.itemAt(1); this.delete(i);
        return i;
    }
    
    delete(i) {
        if (!this.contains(i)) return;
        let j = this.itemAt(this.#m--);
        if (i != j) {
            if (this.#key[j] <= this.#key[i])
                this.#siftup(j, this.#pos[i]);
            else
                this.#siftdown(j, this.#pos[i]);
        }
        this.#pos[i] = 0;
    }
    
    #siftup(i, x) {
        let px = this.p(x);
        while (x > 1 && this.#key[i] < this.#key[this.itemAt(px)]) {
            this.#item[x] = this.itemAt(px); this.#pos[this.itemAt(x)] = x;
            x = px; px = this.p(x);
        }
        this.#item[x] = i; this.#pos[i] = x;
    }
    
    #siftdown(i, x) {
        let cx = this.#minchild(x);
        while (cx != 0 && this.#key[this.#item[cx]] < this.#key[i]) {
            this.#item[x] = this.#item[cx]; this.#pos[this.#item[x]] = x;
            x = cx; cx = this.#minchild(x);
        }
        this.#item[x] = i; this.#pos[i] = x;
    }
    
    #minchild(x) {
        let minc = this.left(x);
        if (minc > this.m) return 0;
        for (let y = minc + 1; y <= this.right(x) && y <= this.m; y++) {
            if (this.#key[this.#item[y]] < this.#key[this.#item[minc]])
                minc = y;
        }
        return minc;
    }
    
    changekey(i, k) {
        let ki = this.#key[i] + this.#offset;
        this.#key[i] = k - this.#offset;
             if (k < ki) this.#siftup(i, this.#pos[i]);
        else if (k > ki) this.#siftdown(i, this.#pos[i]);
    }
}
</textarea>
<p>
The running time for <i>siftup</i> is $O(\log_d n)$, while
the running time for <i>siftdown</i> is $O(d \log_d n)$.
The <i>changekey</i> operation can also be implemented using
<i>siftup</i> to reduce the key value and <i>siftdown</i> to increase
the key value. Hence, its running time is either $O(\log_d n)$
or $O(d \log_d n)$, depending on whether the key is increased or
decreased.
In some applications key reductions may occur more frequently than
other operations. In such cases, the overall performance can be
improved by selecting a value of $d$ that makes these operations faster
at the expense of the others.

<a id=fheaps><h2>Fibonacci Heaps</h2></a>

The Fibonacci heaps [FreTar87] data structure represents a collection
of heaps that define a partition over a common index range $1\ldots n$.
Each heap is identified by one of its items.
The data structure supports an efficient <i>meld</i> operation which
combines two heaps into a single heap.
It also can implement a <i>changekey</i> operation that takes
essentially constant time when the key value is reduced;
operations that increase the key value take $O(\log n)$ time.
More precisely, in a sequence of $m$ heap operations including
$d$ <i>delete</i>, <i>deletemin</i> and increasing <i>changekey</i>
operations, the total running time is $O(m + d\log n)$.
<p>
The provided <i>Javascript</i> implementation extends the
<a href="./trees.html#forest">$\Forest$ data structure</a> and
includes the following methods.
<ul>
<li>    $\key(i,k)$ sets the key of item $i$
        to $k$ if $k$ is provided;
        returns the key  of $i$.
<li>    $\findmin(h)$ returns the item of minimum key in the
        heap identified by item $h$.
<li>    $\deletemin(h)$ returns the item of minimum key in the
        heap identified by $h$ and removes it from
        $h$.
<li>    $\delete(i, h)$ deletes $i$ from the
        heap identified by $h$.
<li>    $\meld(h1, h2)$ combines the two heaps identified by
        $h_1$ and $h_2$ and returns the identifier of
        the combined heap.
<li>    $\insert(i, h, k)$ inserts $i$ into the
        heap identified by $h$ with key $k$.
<li>    $\changekey(i, h, k)$ changes the key of item
        $i$ in the heap identified by $h$
        to $k$.
</ul>
Each heap in the data structure is represented by a <i>collection</i>
of heap-ordered trees.
The trees forming a heap are implemented as a <i>tree group</i> in
the <a href="./trees.html#forest"><i>forest</i></a> data structure.
Each heap item has a <i>key</i> and two auxiliary fields,
a <i>rank</i> and a <i>mark</i>. For each item $i$,
$\rank(i)$ equals the number of children of $i$.
The figure below shows a single heap consisting of three trees.
Note that marks are shown by the presence or absence of check symbol.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/fheaps1.png"><br>
</div>
<p>
<p>
The root of the first tree in the tree group defining a heap is
used as the heap identifier.
This is also an item with the smallest key.
Two heaps can be melded simply by combining their groups.
An insert is essentially just a meld of a singleton heap with another heap.
<p>
The $\deletemin$ operation for a heap identified by $h$
is implemented by removing each of $h$'s subtrees and adding
them as additional trees in the heap; $h$ is then removed
from the tree group.
Next, the roots of the trees still in the heap are scanned to find the root
with the smallest key.
The heap is restructured at the same time to speed up later operations.
In particular, trees with roots of equal rank are combined, with one tree
becoming a subtree of the other's root.
This is illustrated below.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/fheaps2.png"><br>
</div>
<p>
This procedure can be implemented
by inserting each tree root into an array at the position determined by
its rank.
Whenever such an insertion would <i>collide</i> with a previously inserted
root, the two trees are combined with one becoming the subtree of
the other tree's root (based on key value).
The root that was previously in the array is removed and
the root of the new tree is inserted at the position determined
by its new rank. If this leads to a new collision, the process is repeated.
<p>
This restructuring process reduces the number of trees, speeding up
subsequent $\deletemin$ operations.
It also leads to a useful property, that can be
observed in the example above. Note that after the process completes,
the root node has a rank of 3, while its children have ranks of 2, 1 and 0,
respectively. 
Also observe, that every node in the tree with a rank of $k$ has $2^k$
nodes in its subtree. 
This leads to an upper bound of $\lg n$ on the rank of any node.
<p>
Before discussing the $\changekey$ operation, let's analyze
the performance of a sequence of $\insert$ and
$\deletemin$ operations only.
Let's start by showing that the property observed in the example
is in fact a general property.
<p>
<i>Lemma 1</i>. Let $x$ be any node with rank $r$ and children $y_1,\ldots,y_r$,
where the children are listed in the order that they became children of $x$.
Then, $\rank(y_i) \geq i-1$.
<p>
<i>Proof</i>.
First note, that if the only operations are $\insert$ and 
$\deletemin$, then only tree roots are ever removed from a heap.
That means that no node in the heap ever loses a child.
Also, a node can only become the child of another during the
restructuring process performed by the $\deletemin$ operation.
Consequently, just before $y_i$ became a child of $x$, $x$ had
$i-1$ children. Since $y_i$ became a child of $x$ it must have collided
with $x$ during the restructuring process and hence it must have had
$i-1$ children, and since it hasn't lost any children
it must still have $i-1$. $\Box$
<p>
<i>Corallary 1</i>. A node $x$ with rank $r$ has $2^r$ descendants in
its subtree.
<p>
<i>Proof</i>. The proof is by induction on the rank, and clearly holds for
$r=0$. For $r > 0$, the induction hypothesis and lemma imply that $x$ has
$1 + 2^0+2^1+\cdots+2^{r-1} = 2^r$ descendants. $\Box$
<p>
This implies that the maximum rank is $\leq \lg n$,
and that can be used to show that the initialization of the
data structure followed by any sequence $m$ operations
including $d$ $\deletemin$ operations
takes $O(n + m + d\log n)$ time.
This is done using a form of <i>amortized analysis</i> in which a set
fictitious <i>credits</i> are allocated for each operation and
used to &ldquo;pay&rdquo; for computational steps.
Credits that are not needed to pay for a particular operation can be saved
and used to pay for later operations. To ensure that there are always
enough credits available, the algorithm adopts the following
<i>credit policy</i>
<p style="padding-left:5%;">
Maintain one credit on-hand for every tree in all the heaps.
<p>
Note that the initialization of the data structure takes $O(n)$ time
and leaves us with exactly $n$ trees. So, if $2n$ credits are allocated
for the initialization, $n$ can be used to pay for the computation,
leaving us with $n$ credits that can be used to satisfy the credit
policy.
Since an $\insert$ operation takes constant time and does not
change the number of trees, a single credit can be allocated for each
$\insert$ and used to pay for the operation.
<p>
For the $\deletemin$ operation the time required is
bounded by the number of trees at the start of the restructuring process.
If the deleted item has rank $r$,
then the first step increases the number of trees by $r$, while the
restructuring process may decrease the number of trees.
If $p$ is the number of restructuring steps that involve a collision
and $q$ is number that do not, then the total number of steps is $p+q$
and the number of trees at the completion of the process is $r-p$
larger than at the start. So, to pay for the operation and ensure
that the credit policy is satisfied, $(p+q)+(r-p)=q+r$ credits must
be allocated to the $\deletemin$ operation.
To account for the case where $q$ and $r$ are both zero, one extra
credit is allocated, and
since both $q$ and $r$ are bounded by the maximum rank,
$1+ 2\lg n$ credits are enough to pay for the operation and
maintain the credit invariant.
<p>
This implies that the total number of credits allocated
for the initialization plus
$m$ operations including
$d$ $\deletemin$ operations is
$O(n+m+d\log n)$.
Since every computational step was paid for from allocated credits,
the running time is also $O(n+m+d\log n)$.
<p>
Now, it's time to consider the $\changekey(i,h,k)$
operation.  When decreasing the key value, it can be
implemented by first changing the key value, removing the subtree
at $i$ and making it another tree in the heap's tree group.
This is a perfectly fine way of implementing $\changekey$
but has the unfortunate side effect of breaking the analysis just
completed. In particular, the key lemma requires that no item ever
loses a child.
<p>
Fortunately, an alternate version of the lemma can be applied if
the operation is modified to ensure that no non-root
item loses more than one child.
The new version sets the mark bit of
a node $x$ whenever $x$ loses one of its children. If $x$ is
already marked when $x$ loses a child,
the subtree at $x$ is also removed and added to the heap's tree group
(assuming $x$ is not already a tree root).
If $x$'s parent is already marked, its subtree
is also removed and added to the heap's tree group.
This procedure is repeated until the parent of the subtree being
removed is unmarked or is a root.
The mark bits of all the new tree roots are cleared.
This process is illustrated below.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/fheaps3.png"><br>
</div>
<p>
Here is the new version of the lemma.
<p>
<i>Lemma 2</i>. Let $x$ be any item with rank $r$ and children $y_1,\ldots,y_r$,
where the children are listed in the order that they became children of $x$.
Then, $\rank(y_i) \geq i-2$.
<p>
<i>Proof</i>.
As before, note that an item becomes the child of another during the
restructuring process performed by the $\deletemin$ operation.
Consequently, just before $y_i$ became a child of $x$, $x$ had
at least $i-1$ children. Since $y_i$ became a child of $x$ it must have collided
with $x$ during the restructuring process and hence it must have had
at least $i-1$ children, and since it has lost no more than one child
since it became a child of $x$, it must still have at least $i-2$. $\Box$
<p>
<i>Corallary 2</i>. An item $x$ with rank $r$ has at least $F_r$ descendants in
its subtree, where $F_r$ is the $r$-th Fibonacci number.
<p>
<i>Proof</i>. 
The proof is by induction on the rank, and clearly holds for
$r=0$ and $r=1$. For $r > 1$, the induction hypothesis and
lemma imply that $x$ has
at least $1 + F_0 + F_1 + \cdots + F_{r-2}$ descendants.
This sum is equal to $F_r$. $\Box$
<p>
The Fibonacci numbers satisfy the inequality $F_r \geq \phi ^{r-2}$
where $\phi = (1 + \sqrt{5})/2$. Consequently, the maximum rank
is $\leq 2 + \log_\phi n$.
<p>
To complete the analysis, the amortized complexity argument must be
extended to handle the decreasing $\changekey$ operation.
Here is a modified version of the credit policy.
<p style="padding-left:5%;">
Maintain one credit on-hand for every tree in all the heaps
plus two credits for every marked non-root item.
<p>
As before, if $2n$ credits are allocated
for the initialization, $n$ can be used to pay for the computation,
and the remainder is enough to satisfy the credit policy.
<p>
Since an $\insert$ or $\meld$ operation takes
constant time and does not change the number of trees or the number of
marked item, a single credit can be allocated for each
$\insert$ or $\meld$ and used to pay for the operation.
<p>
Since the $\deletemin$ operation makes no change to the number
of marked items, the previous argument can be applied directly.
The only change required is that the number of credits allocated to the step
must increased to $1 +  2(2+\log_\phi n)$.
<p>
To determine the number of credits needed for
a decreasing $\changekey$ operation,
let $k$ be the number of new subtrees created by the
operation. Observe that the number of marked non-root items decreases
by $k-1$, while the number of trees increases by $k$.
Consequently, $k-2$ fewer credits are needed to satify the credit policy
following the operation.
These $k-2$ credits plus 2 more are sufficient to pay for
the computational steps.
<p>
All that remains is to analyze the $\delete$ and the
increasing $\changekey$. These can both be implemented in terms
of the other operations. Specifically,
the $\delete$ operation can be implemented by doing
a decreasing $\changekey$ followed by a $\deletemin$.
The increasing $\changekey$ can be implemented as a
$\delete$ followed by an $\insert$.
Consequently
the total number of credits allocated for the initialization plus
$m$ heap operations that include 
$d$ $\delete$, $\deletemin$ and increasing
$\changekey$ operations is $O(n+ m + d\log n)$.
Since every computational step is paid for with allocated credits,
the running time is also $O(n+m+d\log n)$.
If $m\geq n$ (as it usually is), the bound can expressed more
simply as $O(m+d\log n)$.
<p>
The core methods of the $\FibHeaps$ class are shown below.
<p>
<textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class FibHeaps extends Forest {
    #key;        // #key[i] is key of item i
    #rank;        // #rank[i] gives rank of item i
    #mark;        // #mark[i] is true if item i is considered marked

    #rankVec;    // #rankVec is an auxiliary array used during restructuring
    #tmpq;        // #tmpq is a List object used as a temporary queue 

    #MAXRANK = 32;

    constructor(n=10) {
        super(n);
        this.#key = new Float32Array(this.n+1);
        this.#rank = new Int32Array(this.n+1);
        this.#mark = new Int8Array(this.n+1);
        this.#rankVec = new Int32Array(this.#MAXRANK+1);
        this.#tmpq = new List(this.n);
    }

    key(i, v=false) {
        if (v !== false) this.#key[i] = v;
        return this.#key[i];
    }

    rank(i, r=false) {
        if (r !== false) this.#rank[i] = r;
        return this.#rank[i];
    }

    mark(i, m=-1) {     
        if (m != -1) this.#mark[i] = m;
        return this.#mark[i];
    }

    c(i) { return this.firstChild(i); }

    findmin(h) { return h; }

    meld(h1, h2) {
        if (h1 == 0) return h2;
        if (h2 == 0 || h1 == h2) return h1;
        return (this.key(h1) <= this.key(h2) ?
                    this.joinGroups(h1, h2) : this.joinGroups(h2, h1));
    }

    insert(i, h, k) {
        if (i > this.n) this.expand(i);
        this.key(i,k); return this.meld(i, h);
    }
    
    changekey(i, h, k) {
        if (k > this.key(i)) {
            h = this.delete(i, h);
            return this.insert(i, (h != 0 ? h : i), k);
        }
        this.key(i,k);
        if (this.p(i) == 0) {
            if (this.key(h) > this.key(i)) {
                this.rotate(h,i); h = i;
            }
            return h;
        }
        let pi = this.p(i);
        if (this.key(i) >= this.key(pi)) return h;
        do {
            this.cut(i); this.rank(pi,this.rank(pi)-1);
            this.mark(i,false);
            h = this.meld(h, i);
            i = pi; pi = this.p(i);
        } while (this.mark(i)); // note: if i is marked, it's not a root
        if (pi != 0) this.mark(i,true);
        return h;
    }

    /** Merge the tree roots in heap, to eliminate repeated ranks.
     *  @param r0 is the first tree root in a tree group for a heap;
     *  it is called after the node with the smallest key is removed from heap
     *  @return the root of the the tree root with the smallest key,
     *  following the merging
     */
    #mergeRoots(r0) {
        let key = this.#key; let rank = this.#rank;
        let tmpq = this.#tmpq; let rvec = this.#rankVec;

        // Build queue of roots and find root with smallest key
        let minRoot = r0;
        for (let sr = r0; sr; sr = this.nextSibling(sr)) {
            if (key[sr] < key[minRoot]) minRoot = sr;
            tmpq.enq(sr); this.mark(sr,false);
        }
        r0 = this.rotate(r0, minRoot); // r0 is now min root
        // scan roots, merging trees of equal rank
        let maxRank = -1; // maxRank = maximum rank seen so far
        while (!tmpq.empty()) {
            let r1 = tmpq.pop(); let r2 = rvec[rank[r1]];
            let rank1 = rank[r1];
            if (maxRank < rank1) {
                rvec[rank1] = r1;
                for (maxRank++; maxRank < rank1; maxRank++)
                    rvec[maxRank] = 0;
            } else if (r2 == 0) {
                rvec[rank1] = r1;
            } else if (key[r1] < key[r2] || (key[r1] == key[r2] && r1 == r0)) {
                this.ungroup(r2,r0);
                this.link(r2,r1); tmpq.enq(r1);
                rvec[rank1] = 0; rank[r1]++;
            } else {
                this.ungroup(r1,r0);
                this.link(r1,r2); tmpq.enq(r2);
                rvec[rank1] = 0; rank[r2]++;
            }
        }
        return r0;
    }
        
    deletemin(h) {
        // Move h's children into root list and delete h
        for (let i = this.firstChild(h); i; i = this.firstChild(h)) {
            this.cut(i); this.joinGroups(h,i);
        }
        this.rank(h,0);
        if (!this.nextSibling(h)) return [h,0];
        let r = this.ungroup(h,h); // r is first root remaining in tree group
        return [h, (r ? this.#mergeRoots(r) : 0)];
    }
    
    delete(i, h) {
        let k = this.key(i);
        h = decreasekey(i, (this.key(i) - this.key(h)) + 1, h);
        h = deletemin(h);
        this.key(i,k);
        return h;
    }
}
</textarea>

<a id=lheaps><h2>Leftist Heaps</h2></a>

As with Fibonacci heaps, the leftist heaps [Crane72, Knuth73] data structure
maintains a collection of meldable heaps which define a partition over a
common index range $1\ldots n$.
Each heap is identified by one of its items.
In its basic form, the running time of all the standard heap operations
is $O(\log n)$.
<p>
The <i>Javascript</i> implementation includes the following methods.
<ul>
<li>    $\key(i,k)$ sets the key of item $i$
        to $k$ if $k$ is provided;
        returns the key of $i$.
<li>    $\findmin(h)$ returns the item of minimum key in the
        heap identified by item $h$.
<li>    $\deletemin(h)$ returns the item of minimum key in the
        heap identified by $h$ and removes it from
        $h$.
<li>    $\meld(h1,h2)$ combines the two heaps identified by
        $h_1$ and $h_2$ and returns the identifier of
        the combined heap.
<li>    $\insert(i,h,k)$ inserts $i$ into the
        heap identified by $h$ with key $k$.
<li>    $\heapify(l)$ combines the heaps in the list $l$
        into a single heap.
</ul>
The data structure represents each heap using a heap-ordered binary tree
and can be implemented using the
<a href="./trees.html#binaryForest"><i>binary forest</i></a> data structure.
Each item has an associated <i>rank</i> field.
The item with index 0 is assigned a rank of 0.
For all other nodes, the rank value is one plus the minimum of
the ranks of its two children.
The trees are structured so that whenever a node's children have
unequal ranks, the node with the larger rank is placed on the left.
This ensures that the shortest path from any tree node to the <i>null</i>
node is the path defined by following right pointers. 
<p>
<div  style="text-align:center;">
<img width="35%" src="figs/lheap1.png"><br>
</div>
<p>
The $\meld$ operation is implemented by merging the right-most paths
of the two heaps, based on the key values,
then updating the ranks along the merge path, swapping
left and right children as needed to ensure that the larger rank value
is always to the left. This is illustrated below.
<p>
<div  style="text-align:center;">
<img width="90%" src="figs/lheap2.png"><br>
</div>
<p>
The $\insert$ operation is implemented by treating the item
to be inserted as a single node heap and melding it with the heap it is
to be inserted into.
The $\deletemin$ operation is implemented by removing the
root node and melding its two subtrees.
The $\heapify$ operation is implemented by
repeatedly removing the first two heaps from the list, melding them
then appending the resulting heap at the end of the list.
It terminates when there is a single heap on the list.
Since the length of the right path from any node to the <i>null</i> node
is at most $\lg n$, the $\meld$, $\insert$ and
$\deletemin$ operations all take $O(\log n)$ time.
<a id="heapify">The analysis of $\heapify$</a>
is a bit more complicated.
The first step is to divide the processing into <i>passes</i>,
where a pass ends when all the heaps on the list at the start of the
pass have been removed and melded with some other heap.
If there are $k$ heaps on the list intially, the number of passes is
at most $\lg k$, since each pass reduces the number of heaps by
a factor of 2. If there are $r$ heaps on the list at the end of
a pass and the heap sizes are $n_1, n_2,\ldots, n_r$, then the time
for the pass is
$$
O \left(\log n_1 + \cdots + \log n_r \right) = O \left( r \log n/r \right)
$$
since the value of the sum is maximized when all heaps are the same size.
Consequently, the total time for $\heapify$ is
$$
\begin{eqnarray*}
O\left( \sum_{j=1}^{\lfloor \lg k \rfloor} (k/2^j) \log ( 2^j n/k) \right) &=&
O\left( k \sum_{j=1}^{\lfloor \lg k \rfloor} (j/2^j) + (1/2^j) \log ( n/k) \right) \\
&=& O\left( k\max(1, \log(n/k)) \right)
\end{eqnarray*}
$$
The core methods of the <i>Javascript</i> implementation
are shown below.
<p>
<textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class LeftistHeaps extends BinaryForest {
    #key;        // #key[i] is key of item i
    #rank;        // #rank[i] gives rank of item i

    constructor(n=10) {
        super(n);
        this.#key = new Float32Array(this.n+1)
        this.#rank = new Int32Array(this.n+1).fill(1,1);
    }

    key(i, k=false) {
        if (k !== false) this.#key[i] = k;
        return this.#key[i];
    }

    rank(i, r=false) {
        if (r !== false) this.#rank[i] = r;
        return this.#rank[i];
    }

    meld(h1, h2) {
        // relies on null node having rank==0
        if (h1 == 0) return h2;
        if (h2 == 0 || h1 == h2) return h1;
        if (this.key(h1) > this.key(h2)) {
            let h = h1; h1 = h2; h2 = h;
        }
        this.link(this.meld(this.right(h1), h2), h1, +1);

        if (this.rank(this.left(h1)) < this.rank(this.right(h1))) {
            let h = this.left(h1);
            this.link(this.right(h1),h1,-1);
            this.link(h,h1,+1);
        }
        this.rank(h1, this.rank(this.right(h1)) + 1);
        return h1;
    }

    insert(i, h, k) {
        fassert(this.valid(i) && this.valid(h));
        fassert(this.left(i) == 0 && this.right(i) == 0 && this.rank(i) == 1);
        this.key(i, k);
        return this.meld(i, h);
    }
    
    findmin(h) { return h; }

    deletemin(h) {
        let lh = this.left(h); let rh = this.right(h);
        if (lh) this.cut(lh); if (rh) this.cut(rh);
        let hnew = this.meld(lh, rh);
        this.#rank[h] = 1;
        return [h,hnew];
    }

    heapify(hlist) {
        if (hlist.empty()) return 0;
        while (hlist.length > 1) {
            let h = this.meld(hlist.at(1), hlist.at(2));
            hlist.deq(); hlist.deq(); hlist.enq(h);
        }
        return hlist.first();
    }
}
</textarea></p>

<h3>Lazy Variant</h3>
The basic leftist heap data structure can be extended to include
a <i>lazy deletion</i> operation called $\retire$
and a <i>lazy melding</i> operation.
The $\retire$ operation can be implemented by marking the
tree node for an item, but leaving it in place.  
The $\lazyMeld$ operation can be implemented similarly,
using a <i>dummy node</i> with a key of minus infinity,
and making the two heaps to be combined, children of this dummy node.
<p>
The presence of retired or dummy nodes means that the
&ldquo;true&rdquo; minimum key node may not be at the root of a heap.
Consequently,
the $\findmin$ and $\deletemin$ operations must start
with an initial step that traverses the top of the heap, removing all
the retired/dummy nodes that it finds and constructing a list of sub-heaps
for which the roots are not retired or dummy.
This is illustrated below, with retired/dummy nodes shown in yellow.
<p>
<div  style="text-align:center;">
<img width="90%" src="figs/lheap3.png"><br>
</div>
This list of heaps is then merged into a single heap using $\heapify$.
<p>
Heap items can also be retired implicitly, using a
a client-provided <i>retired</i> function.
If such a function is provided, it is used to determine if a
node should be considered retired, instead of consulting a stored bit.
This eliminates the time spent marking nodes as retired and
is particularly useful if a single step in an application may make many
heap nodes no longer relevant at the same time. Rather than force the
application to identify and mark each of these nodes, it can be more
efficient to identify them with a function call when it's time to purge
them from the heap-ordered tree.
<p>
The core methods of the $\LeftistHeaps$ class are shown below.
<p>
<textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class LazyHeaps extends LeftistHeaps {
    nn;          // largest valid index for a non-dummy node
    #dummy;      // first node in list of free dummy nodes
    #retired;    // #retired is either a user-supplied function
                 // or an array of bits
    #plist;      // temporary list used by purge

    constructor(n=20, retired=null) {
        super((n&1) ? n+1 : n); this.nn = this.n/2;

        for (let i = this.nn+1; i <= this.n; i++) this.rank(i,-1);
        this.#plist = new List(this.nn);
        if (retired != null) this.#retired = retired;
        else this.#retired = new Int8Array(this.n+1).fill(false);

        // implement list of dummy nodes as a tree
        for (let i = this.nn+1; i < this.n; i++) this.link(i+1,i,1);
        this.#dummy = this.nn+1;

    }

    isdummy(i) { return i > this.nn; }

    isactive(i) { return i <= this.nn && !this.retired(i); }

    retire(i) {
        if (this.#retired.constructor != 'function')
            this.#retired[i] = true;
    }

    retired(i) {
        return i <= this.nn &&
                        (typeof this.#retired == 'function' ?
                            this.#retired(i) : this.#retired[i]);
    }

    findmin(h) {
        this.#plist.clear(); this.#purge(h);
        return this.heapify(this.#plist);
    }

    deletemin(h) {
        h = this.findmin(h);  // purges top of heap
        let lh = this.left(h); let rh = this.right(h);
        if (lh) this.cut(lh); if (rh) this.cut(rh);
        let hnew = this.lazyMeld(lh,rh);
        this.rank(h,1);
        return [h,hnew];
    }

    #purge(h) {
        if (h == 0) return;
        fassert(this.valid(h));
        if (this.isactive(h)) {
            this.#plist.enq(h);
        } else {
            this.#purge(this.left(h)); this.#purge(this.right(h));
            if (this.isdummy(h)) {
                this.link(this.#dummy, h, +1); this.#dummy = h;
            }
            this.rank(h,-1);
        }
        if (this.p(h)) this.cut(h); 
    }

    lazyMeld(h1, h2) {
        if (h1 == 0) return h2;
        if (h2 == 0) return h1;
        fassert(this.valid(h1));
        fassert(this.valid(h1) && this.valid(h2) && this.#dummy);
        if (this.rank(h1) < this.rank(h2)) {
            let h = h1; h1 = h2; h2 = h;
        }
        let d = this.#dummy; this.#dummy = this.right(d);
        this.cut(this.#dummy);
        this.join(h1,d,h2);
        this.rank(d, this.rank(h2) + 1);
        this.key(d, Number.NEGATIVE_INFINITY);
        return d;
    }
}
</textarea>
<p>

<h2>References</h2>
<dl>
<dt> [Crane72]
<dd>  &ldquo;Linear lists and priority queues as balanced binary trees,&rdquo;
    by C. A. Crane. Tech. Rep. STANCS-72-259, Computer Science Dept.,
    Stanford Univ., Stanford, CA, 1972.
<dt> [FreTar87]
<dd> &ldquo;Fibonacci Heaps and Their Uses in Improved Nework Optimization
    Algorithms,&rdquo; by Michael Fredman and Robert E. Tarjan,
    <i>Journal of the ACM</i>, 1987.
<dt> [Knuth73]
<dd> <i>The Art of Computer Programming, Vol. 3: Sorting and Searching</i>,
    by D. E. Knuth, Addison-Wesley, Reading, MA, 1973
<dt> [Tarjan87]
<dd> <i>Network Algorithms and Data Structures</i> by Robert E. Tarjan.
     Society for Industrial and Applied Mathematics, 1987.
</dl>
<hr> <h4>&copy; Jonathan Turner - 2022</h4>
<script src="../googleAnalytics.js"></script>
</body>
</html>
