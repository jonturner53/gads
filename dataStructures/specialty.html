<html>
<head>
<title>Specialty</title>
<link type="text/css" rel="stylesheet" href="../main.css">
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>

<body bgcolor=ffffff>
\(
\newcommand{\key}{\texttt{key}}
\newcommand{\changekey}{\texttt{changekey}}
\newcommand{\addtokeys}{\texttt{add2keys}}
\newcommand{\insert}{\texttt{insert}}
\newcommand{\insertAfter}{\texttt{insertAfter}}
\newcommand{\delete}{\texttt{delete}}
\newcommand{\findmin}{\texttt{findmin}}
\newcommand{\deletemin}{\texttt{deletemin}}
\newcommand{\divide}{\texttt{divide}}
\newcommand{\minkey}{\texttt{minkey}}
\newcommand{\activate}{\texttt{activate}}
\newcommand{\deactivate}{\texttt{deactivate}}
\newcommand{\refresh}{\texttt{refresh}}
\newcommand{\findroot}{\texttt{findroot}}
\newcommand{\findcost}{\texttt{findcost}}
\newcommand{\addcost}{\texttt{addcost}}
\newcommand{\graft}{\texttt{graft}}
\newcommand{\prune}{\texttt{prune}}
\newcommand{\expose}{\texttt{expose}}
\newcommand{\succ}{\texttt{succ}}
\newcommand{\findpath}{\texttt{findpath}}
\newcommand{\findtail}{\texttt{findtail}}
\newcommand{\findpathcost}{\texttt{findpathcost}}
\newcommand{\addpathcost}{\texttt{addpathcost}}
\newcommand{\join}{\texttt{join}}
\newcommand{\split}{\texttt{split}}
\newcommand{\cost}{\texttt{cost}}
\newcommand{\dmin}{\texttt{dmin}}
\newcommand{\dcost}{\texttt{dcost}}
\newcommand{\mincost}{\texttt{mincost}}
\newcommand{\splay}{\texttt{splay}}
\newcommand{\rank}{\texttt{rank}}
\)

<h1>Specialty Data Structures<sup>&copy;</sup></h1>

The data structures in this section are designated &ldquo;specialty&rdquo;
because they were designed to enable efficient
implementation of specific algorithms and are consequently
somewhat idiosyncratic. While the line between specialty and
more general-purpose data structures is admittedly fuzzy
(and subjective), it seems sensible to put these in a separate
category.

<h2>Group Heap</h2>

The <i>group heap</i> data structure was originally devised to enable a
specific algorithm for the weighted matching problem in general graphs [GMG86].
The version described here uses a different implementation to make it easier
to explain, and to get a better fit with the other data structures in
this collection.
<p>
The group heap implements a collection of items
that are divided into <i>groups</i>. Each item has a <i>key</i> and
each group may be either <i>active</i> or <i>inactive</i>.
Items within active groups are also called active.
Certain operations treat the collection of active
items like a heap. For example, there is a $\findmin$ operation
that returns the active item with the smallest key value.
Each group defines an ordering over the items within it
and items may be inserted into a group at a specified position
within this ordering. The data structure defines the following methods.
<ul>
<li> $\activate(g)$ makes group $g$ active.
<li> $\deactivate(g)$ makes $g$ inactive.
<li> $\findmin()$ returns an active item with the smallest key.
<li> $\addtokeys(\Delta)$ adds $\Delta$ to the keys of all active items.
<li> $\insertAfter(i,g,k,j)$ inserts item $i$ into group
    $g$ with key $k$, immediately after item $j$.
<li> $\delete(i,g)$ removes item $i$ from group $g$.
<li> $\divide(g,i,g_0)$ divides group $g$ into two
    parts, the items that precede $i$ and the remaining items.
    On return, the first subgroup is identified as $g_0$ while the
    remainder is identified as $g$.
</ul>
The groups are identified by group numbers assigned by the client code;
their values do not correspond to items within the groups.
<p>
The group heap can be implemented using an array heap $A$ to keep track
of the active groups; the key of an active group $g$ is the smallest
key value assigned to any of the items in $g$.
The collection of groups is implemented using a separate
<i>ordered heaps</i> data structure, which represents a collection of
heaps in which the items within each heap are ordered
relative to one another; it provides the following methods.
<ul>
<li>    $\key(i,h)$ returns the key of item $i$
        in heap $h$.
<li>    $\changekey(i,h,k)$ changes the key of item $i$
        in heap $h$ to $k$.
<li>    $\addtokeys(\Delta,h)$ adds increment $\Delta$
        to the keys of all items in heap $h$.
<li>    $\insert(i,h,k)$ inserts item $i$ into heap
        $h$ with key $k$.
<li>    $\insertAfter(i,h,k,j)$ inserts item $i$ into heap
        $h$ with key $k$, placing it immediately
        after item $j$.
<li>    $\delete(i,h)$ deletes item $i$ from heap $h$.
<li>    $\findmin(h)$ returns an item of minimum key in
        heap $h$.
<li>    $\deletemin(h)$ deletes an item of minimum key from
        heap $h$ and returns the pair $[i,h']$
        where $i$ is the deleted item and
        $h'$ is the id of the modified heap.
<li>    $\divide(i,h)$ divides heap $h$ into two parts,
        the items preceding item $i$ and the remaining items.
        The relative order of items within the two new heaps is maintained.
</ul>
A complete description of the ordered heaps data structure appears
in the next section. For now, let's focus on how it is used to implement
the group heap.
<p>
The $\findmin$ operation for the group heap can be implemented by first
finding the active group $g_0$ with the smallest key in
$A$, then finding the item with the smallest key within 
$g_0$. The $\addtokeys(\Delta)$ operation can be implemented
using the $\addtokeys$ operation of $A$.
<p>
Activating a group $g$ is accomplished by inserting $g$ into $A$.
Deactivation removes the specified group from $A$.
Note that both $A$ and the heaps for the individual
groups have offsets that are used to implement $\addtokeys$.
The figure below shows a group heap with two active groups,
$x$ and $y$ and a single inactive group
$z$.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/gheap1.png"><br>
</div>
<p>
Note that while the stored key value for $b$ is 1,
the &ldquo;true&rdquo; value is 4. This is the value stored
in $A$ for group $y$. A $\findmin$ operation on
this group heap will return $c$, after using
$A$ to identify group $x$ and then
$x$'s heap to identify $c$.
<p>
Changes to $A$'s offset must be reflected in the 
offsets of the active groups, but not the inactive groups.
So, before an operation is performed on an active group $g$,
changes to $A$'s offset that have occurred since the
most recent operation affecting $g$ are propagated to
$g$'s offset. After the offset for $g$ is updated,
the value of $A$'s offset is saved, to enable the next update to
$g$'s offset. This process is illustrated below.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/gheap2.png"><br>
</div>
<p>
The core of the <i>Javascript</i> implementation is shown below.
<p><textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class GroupHeap extends Top {
    gn;           // index range for group identifiers

    groups;       // OrderedHeaps data structure with a heap for each group.
    top           // top[g] is the item at the top of heap for group g
    active;       // ArrayHeap of active groups, with
                  // key(g)=the smallest key of any item in group g
    lastOffset;   // for an active group b, lastOffset[b] is the value of
                  // active.offset, when b was last modified or became active

    constructor(n=10, gn=5) {
        super(n); this.gn = gn;

        this.groups = new OrderedHeaps(n);
        this.active = new ArrayHeap(gn);
        this.top = new Int32Array(gn+1);
        this.lastOffset = new Float32Array(gn+1);

        this.steps = 0;
    }

    /** Determine if a group is active. */
    isactive(g) { return this.active.contains(g); }

    /** Check for item in an active group */
    contains(i, g) {
        return this.isactive(g) ? this.groups.contains(i, this.top[g]) : false;
    }

    /** Get the key of an item in a group.  */
    key(i, g) {
        if (this.isactive(g)) this.#updateKeys(g);
        return this.groups.key(i, this.top[g]);
    }

    /** Update the keys of an active group.  */
    #updateKeys(g) {
        if (this.top[g]) {
            this.groups.add2keys(this.active.offset - this.lastOffset[g],
                                  this.top[g]);
        }
        this.lastOffset[g] = this.active.offset;
    }

    activate(g) {
        let h = this.top[g];
        fassert(h, 'GroupHeap.activate requires a non-empty heap');
        this.active.insert(g, h ? this.key(this.groups.findmin(h),g) :
                                           Infinity);
        this.lastOffset[g] = this.active.offset;
    }

    deactivate(g) { this.#updateKeys(g); this.active.delete(g); }

    findmin() {
        let g = this.active.findmin();
        if (!g) return 0;
        this.#updateKeys(g);
        return this.groups.findmin(this.top[g]);
    }

    add2keys(delta) { this.active.add2keys(delta); }

    insertAfter(i, g, k, i0) {
        if (this.isactive(g)) this.#updateKeys(g);
        let h = this.top[g];
        this.top[g] = this.groups.insertAfter(i, h, k, i0);
        if (this.isactive(g) && k < this.active.key(g)) {
            this.active.changekey(g, k);
        }
    }

    delete(i, g) {
        if (this.isactive(g)) this.#updateKeys(g);
        this.top[g] = this.groups.delete(i, this.top[g]);
        if (this.isactive(g)) {
            let h = this.top[g];
            if (!h) {
                this.deactivate(g);
            } else {
                let min = this.key(this.groups.findmin(h), g);
                if (this.active.key(g) != min)
                    this.active.changekey(g, min);
            }
        }
    }

    divide(g, i, g0) {
        if (this.isactive(g)) {
            this.#updateKeys(g); this.deactivate(g);
        }
        if (i == 0) {
            this.top[g0] = this.top[g]; this.top[g] = 0;
        } else {
            [this.top[g0], this.top[g]] = this.groups.divide(i, this.top[g]);
        }
        if (this.isactive(g) && !this.top[g])
            this.deactivate(g);
    }
}
</textarea><p>
The following code can be used to demonstrate the data
structure in the web app.
<pre style="padding-left:5%;">
let gh = new GroupHeap();
gh.fromString('{1[a:3 b:2] 2@![c:2 d:5 e:1 j:7] 6[f:6 g:3] 4@[i:10]}');
log(gh.toString());
gh.activate(1);
log(gh.toString());
log(gh.x2s(gh.findmin()));
gh.delete(5,2);
log(gh.toString());
gh.delete(3,2);
log(gh.toString());
log(gh.toString(0));
</pre>
This produces the output shown below.
<pre style="padding-left:5%;">
{1[*a:3 b:2] 2@![c:2 *d:5 e:1 j:7] 4@[i:10] 6[*f:6 g:3]} 
{1@[*a:3 b:2] 2@![c:2 *d:5 e:1 j:7] 4@[i:10] 6[*f:6 g:3]} 
e 
{1@[*a:3 b:2] 2@![c:2 *d:5 j:7] 4@[i:10] 6[*f:6 g:3]} 
{1@![*a:3 b:2] 2@[*d:5 j:7] 4@[i:10] 6[*f:6 g:3]}
[a:3 *b:2 d:5 j:7 i:10]
</pre>
By default, the state of the data structure is shown as a collection of
groups, with each group preceded by its group number and
each item shown with its key.
Active groups are marked with an at symbol &lsquo;@&rsquo;
and the active group containing the smallest key is
also marked with a bang &lsquo;!&rsquo;.
The last line shows a more concise representation, in which the
groups are hidden, and only the minimum key item of each active group is
shown, with an asterisk highlighting the item with the smallest key.

<a id=oheaps><h2>Ordered Heaps</h2></a>

The <i>ordered heaps</i> data structure was introduced in the last section.
Recapping, it implements a collection of heaps in which the items within
each heap are ordered relative to one another; it provides the following
methods.
<ul>
<li>    $\key(i,h)$ returns the key of item $i$
        in heap $h$.
<li>    $\changekey(i,h,k)$ changes the key of item $i$
        in heap $h$ to $k$.
<li>    $\addtokeys(\Delta,h)$ adds increment $\Delta$
        to the keys of all items in heap $h$.
<li>    $\insert(i,h,k)$ inserts item $i$ into heap
        $h$ with key $k$.
<li>    $\insertAfter(i,h,k,j)$ inserts item $i$ into heap
        $h$ with key $k$, placing it immediately
        after item $j$.
<li>    $\delete(i,h)$ deletes item $i$ from heap $h$.
<li>    $\findmin(h)$ returns an item of minimum key in
        heap $h$.
<li>    $\deletemin(h)$ deletes an item of minimum key from
        heap $h$ and returns the pair $[i,h']$
        where $i$ is the deleted item and
        $h'$ is the id of the modified heap.
<li>    $\divide(i,h)$ divides heap $h$ into two parts,
        the items preceding item $i$ and the remaining items.
        The relative order of items within the two new heaps is maintained.
</ul>
Unlike most heaps, the ordered heaps data structure is not implemented
using heap-ordered trees. Instead, it uses a balanced
binary forest allowing it to support a list ordering on the heap items.
To enable it to quickly find an item of minimum key, an auxiliary field
$\minkey$ is maintained for each heap item, with
$\minkey[u]$ equal to the smallest key in the subtree
with root $u$. This is illustrated below.
<p>
<div  style="text-align:center;">
<img width="55%" src="figs/oheaps1.png"><br>
</div>
The $\minkey$ field must be updated during rotations.
It must also be <i>refreshed</i> following any other operation that
changes a single key value, adds a heap item or deletes a heap item.
The required $\refresh$ operation follows the path from a
node to the root of the tree, updating the $\minkey$ fields
along its path, based on the key of the current node and the
$\minkey$ fields of its two children.
<p>
<div  style="text-align:center;">
<img width="80%" src="figs/oheaps2.png"><br>
</div>
<p>
The $\addtokeys$ method is implemented by adding the
specified increment to a per-heap offset value.
When an item is inserted into a heap, the saved key value is adjusted
to reflect the offset, so that at all times the sum of the stored key value
and the offset is equal to the user-specified key.
The saved $\minkey$ values also reflect the offset,
so the minimum key in the subtree of an item is equal to
the sum of the stored value and the offset.
<p>
The $\divide$ method is implemented using the $\split$
method of the underlying balanced binary forest data structure.
Note that the split method uses $\join$ operations in its
implementation, so the ordered heap method provides a $\join$ operation
for this specific purpose. The provided $\join$ operation uses the
$\refresh$ operation to maintain the
validity of the $\minkey$ fields.
The provided $\join$ operation does not work in general contexts, since
it requires that the components being joined together all have
the same offset.
<p>
The core of the <i>Javascript</i> implementation appears below.
<p><textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class OrderedHeaps extends BalancedForest {
    #key;           // #key[i] is key of item i
    #minkey;        // #minkey[i] is smallest key within subtree at i 
    #offset;        // offset[h] is a key offset for heap h

    constructor(n=10) {
        super(n);
        this.#key = new Float32Array(this.n+1)
        this.#minkey = new Float32Array(this.n+1)
        this.#offset = new Float32Array(this.n+1)
    }

    /** Get key of a heap item. */
    key(i, h=super.root(i)) { return this.#key[i] + this.#offset[h]; }

    /** Get minkey of a heap item. */
    minkey(i, h=super.root(i)) {
        return this.#minkey[i] + this.#offset[h];
    }

    add2keys(delta, h) { if (h) this.#offset[h] += delta; }

    changekey(i, h, k) {
        this.#key[i] = k - this.#offset[h];
        this.refresh(i);
    }

    insert(i, h, k) {
        return this.insertAfter(i, h, k, this.last(h));
    }

    insertAfter(i, h, k, j) {
        fassert(this.valid(i) && this.valid(j) && this.valid(h));
        if (h == 0) {
            this.#key[i] = this.#minkey[i] = k; return i;
        }
        let offset = this.#offset[h];
        this.#key[i] = k - offset; this.#minkey[i] = this.#key[i];
        h = super.insertAfter(i, h, j, x => this.refresh(x));
        this.#offset[h] = offset;
        return h;
    }

    delete(i, h=this.find(i)) {
        if (this.singleton(i)) return;
        let offset = this.#offset[h];
        // identify an item near the root that is not i
        let hh = (i != h ? h : (this.left(h) ? this.left(h) : this.right(h)));
        super.delete(i, h, pi => this.refresh(pi));
        hh = this.find(hh);
        this.#offset[hh] = offset;
        this.#key[i] += offset; this.#minkey[i] = this.#key[i];
        this.#offset[i] = 0;
        return hh;
    }

    divide(i, h=this.find(i)) {
        let offset = this.#offset[h];
        let [h1,h2] = super.split(i);
        if (h1) this.#offset[h1] = offset;
        if (h2) this.#offset[h2] = offset;
        this.#minkey[i] = this.#key[i]; this.#offset[i] = offset;
        h2 = this.join(0,i,h2);
        this.#offset[h2] = offset;
        return [h1,h2];
    }

    join(t1, u, t2) { return super.join(t1, u, t2, u => this.refresh(u)); }

    refresh(i) {
        while (i) {
            let min = this.#key[i];
            let l = this.left(i); let r = this.right(i);
            if (l) min = Math.min(min, this.#minkey[l]);
            if (r) min = Math.min(min, this.#minkey[r]);
            this.#minkey[i] = min;
            i = this.p(i);
            this.steps++;
        }
    }

    findmin(h, which=0) {
        if (!h) return 0;
        let k = this.#minkey[h];
        let i = h;
        while (i) {
            let l = this.left(i); let r = this.right(i);
            if (this.#key[i] == k) {
                if (which == 0 ||
                    which == -1 && (!l || this.#minkey[l] != k) ||
                    which == +1 && (!r || this.#minkey[r] != k)) {
                    return i;
                }
            }
            i = (l && this.#minkey[l] == k ? l : r);
            this.steps++;
        }
        fassert(false, `program error in OrderedHeaps.findmin(${this.x2s(h)})`);
    }

    deletemin(h) {
        let u = this.findmin(h); h = this.delete(u,h);
        return [u,h];
    }

    rotate(x) {
        let y = this.p(x);
        if (y == 0) return;
        super.rotate(x);
        this.#minkey[x] = this.#minkey[y]; 
        let min = this.#key[y];
        let l = this.left(y); let r = this.right(y);
        if (l)  min = Math.min(min, this.#minkey[l]);
        if (r) min = Math.min(min, this.#minkey[r]);
        this.#minkey[y] = min;
        if (!this.p(x)) this.#offset[x] = this.#offset[y];
    }
}
</textarea><p>

<a id=dtrees><h2>Dynamic Trees</h2></a>
The <i>dynamic trees</i> data structure represents a collection of
trees with each tree node $u$ having a cost denoted $\cost(u)$.
It was invented by Sleator and Tarjan [Tarjan87] to enable faster
implementations of algorithms for the
<a href="../graphAlgorithms/maxflow.html#maxflowST">maximum flow problem</a>.
It provides the following methods.
<ul>
<li>    $\findroot(u)$ returns the root of the tree containing $u$.
<li>    $\findcost(u)$ returns a pair $[v,c]$ where $v$ is the last node
        of minimum cost on the path from $u$ to its tree root and $c$
        is its cost.
<li>    $\addcost(u, c)$ adds $c$ to the costs of all nodes on
        the path from $u$ to the root of its tree.
<li>    $\graft(t, u)$ links the tree with root $t$ to the
        node $u$, making $t$ a subtree of $u$.
<li>    $\prune(u)$ divides the tree containing $u$ by removing the edge
        from $u$ to its parent.
</ul>
An example is shown below, illustrating the effects of a few
of the operations.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/dtrees1.png"><br>
</div>
<p>
In the maximum flow problem, the dynamic trees data structure is
used to represent information about edges in the graph that can
accommodate more flow. Specifically, an edge linking a node $u$
to its parent represents an edge in the &ldquo;flow graph&rdquo;
on which flow can be added. The amount of flow that can be added
to that edge
is represented by the cost of $u$. So any path from a node to
one of its ancestors represents a path in the flow graph along which
flow may be added, with the amount of flow represented by the minimum
cost of the nodes along the path.
<p>
To enable efficient operations on paths in a dynamic tree,
there is a special operation called $\expose$ that isolates a
particular path
from the rest of a tree. In fact, the tree is represented as a collection
of such paths, that are linked together. The example below shows a
tree that is represented in this way and the effect of an expose operation
on that tree.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/dtrees2.png"><br>
</div>
<p>
In the diagram, the solid edges define component paths of the tree
and the dashed edges
represent links joining paths together. A mapping $\succ$ maps a
component path $p$ to its successor node $\succ(p)$. So for example,
in the diagram, if $p$ is the path containing $m$, then $\succ(p)=n$.
Note that a node can have at most one
&ldquo;solid edge&rdquo; joining it to a child and that
$\expose(u)$ turns all the dashed edges on the path from $u$
to the root into solid edges, and all solid edges incident to, but not on the
path, into dashed edges.
<p>
The &ldquo;solid paths&rdquo; in the dynamic trees data structure are defined
using another data structure called a <i>path set</i>.
It supports the following methods.
<ul>
<li> $\findpath(u)$ returns the path containing the node $u$.
<li> $\findtail(p)$ returns the last vertex on path $p$.
<li> $\findpathcost(p)$ returns a pair $[u,c]$ where $u$ is the last node
    of minimum cost on $p$ and $c$ is its cost.
<li> $\addpathcost(p,c)$ adds $c$ to the cost of every node on $p$.
<li> $\join(p_1,u,p_2)$ combines path $p_1$, singleton $u$ and path $p_2$
     to form a new path.
<li> $\split(u)$ divides the path $p$ containing $u$ at $u$ and returns a pair
    $[p_1, p_2]$ where $p_1$ is the part of $p$ that precedes $u$
    and $p_2$ is the part that follows $u$.
</ul>
An example of a path set, with some operations is shown below.
<p>
<div style="text-align:center;">
<img width="65%" src="figs/pathSet1.png"><br>
</div>
<p>
The path sets data structure can be implemented in a way that allows
$m$ operations to be completed in $O(m \log n)$ time. Details appear below.
For now, let's focus on how it can be used to implement the dynamic tree
operations.
<p>
The operation $\findroot(u)$ can be implemented by first doing an
expose at $u$ then a $\findtail$ operation on the resulting path.
Similarly, $\findcost(u)$ (and $\addcost(u)$) can be implemented by
first doing an
expose at $u$ and then a findpathcost (addpathcost).
The operation $\graft(t,u)$ is done by first doing an expose at $t$,
isolating it from the rest of its path, then a second expose at $u$,
isolating the path from $u$ to its tree root,
then a join adding $t$ to that path.
The operation $\prune(u)$ is done by doing a $\split$
on the path containing $u$ and updating successors to account
for the new path components created by the $\split$.
<p>
The expose operation is the key to the dynamic trees data structure.
The diagram below illustrates how it works.
<p>
<div  style="text-align:center;">
<img width="60%" src="figs/expose.png"><br>
</div>
<p>
An $\expose(u)$ operation proceeds up the path from $u$ to the root,
converting dashed edges along the path into solid edges and solid edges
incident to the path into dashed edges.
In each step, one solid path that shares part of the root path is
split, and then the upper part of that path is joined to the solid path
containing $u$. The successors are updated as needed to maintain
the overall tree structure. So in the first step of the above example, the
solid path containing $u$ is split to separate out the portion that
comes before $u$. Then, $u$ is rejoined to the upper part of the path.
In the second step, the solid path containing $v$ is split, then the upper part
of that path is joined with the solid path containing $u$.
This effectively converts a solid edge incident to the path into a dashed
edge and a dashed edge on the path into a solid one. The process continues
in this way until it reaches the root.
<p>
A <i>Javascript</i> implementation of the core methods of
the dynamic trees data structure appears below.
<p> <textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class DynamicTrees extends PathSet {
    constructor(n=10) {
        super(n); this.exposeCount = this.spliceCount = 0;
    }

    expose(u) {
        fassert(this.valid(u));
        let [p,s] = [0,u];
        while (s != 0) {
            [p,s] = this.#splice([p,s]);
        }
        this.succ(p, 0);
        return p;
    }
    
    #splice([p,s]) {
        let next_s = this.succ(super.findpath(s));
        let [p1,p2] = this.split(s);
        if (p1 != 0) this.succ(p1, s);
        let [a,b] = [this.join(p,s,p2), next_s];
        return [a,b];
    }
    
    findroot(u) {
        fassert(this.valid(u));
        let p = this.expose(u);
        let x = this.findtail(p);
        this.succ(x, 0); // works because x is now both tail and path id
        return x;
    }
    
    findcost(u) {
        let [v,c] = super.findpathcost(this.expose(u));
        this.succ(v, 0); // works because v is also now path id
        return [v,c];
    }
    
    addcost(u, c) {
        fassert(this.valid(u));
        this.addpathcost(this.expose(u), c);
    }
    
    graft(t, u) {
        fassert(this.valid(t) && this.valid(u));
        let p = this.expose(u); // id of path from u to tree root
        let sp = this.succ(p);
        this.succ(this.join(0, this.expose(t), p), sp);
    }
    
    prune(u) {
        fassert(this.valid(u));
        let v = this.succ(this.findpath(u));
        let [p,q] = this.split(u);
        if (p != 0) this.succ(p, u);
        if (q != 0) this.succ(q, v);
        this.succ(u, 0);
    }
}
</textarea> <p>
The following code can be used to demonstrate the data
structure in the web app.
<pre style="padding-left:5%;">
let dt = new DynamicTrees();
dt.fromString('{[c:4(f:2(a:5 b:1))] [e:4(g:3(d:2 i:3(h:2)))]}');
log(dt.toString());
dt.expose(1); dt.expose(4);
log(dt.toString(0x12));
dt.graft(3,9);
log(dt.toString(0x12));
</pre>
This produces the output shown below.
<pre style="padding-left:5%;">
{[c:4(f:2(a:5 b:1))] [e:4(g:3(d:2 i:3(h:2)))]} 
{f[b:1] [a:5 f:2 *c:4] [d:2 g:3 *e:4] i[h:2] g[i:3]} 
{f[b:1] [d:2 g:3 *e:4] i[h:2] g[*i:3 a:8 f:5 c:7]} 
</pre>
The first line shows a pair of trees in a concise format,
with each node followed by a parenthesized list of its children.
The remaining lines show each tree as a linked collection of paths.
So for example, the <code>f</code> preceding the path <code>[b:1]</code>
indicates that the <code>f</code> is the successor of this path.

<a id=pathSets><h2>Path Sets</h2></a>
The <i>path sets</i> data structure was introduced in the last section.
Recapping, this data structure supports the following methods.
<ul>
<li> $\findpath(u)$ returns the path containing the node $u$.
<li> $\findtail(p)$ returns the last node on path $p$.
<li> $\findpathcost(p)$ returns a pair $[u,c]$ where $u$ is the last node
     of minimum cost on $p$ and $c$ is its cost.
<li> $\addpathcost(p,c)$ adds $c$ to the cost of every node on $p$.
<li> $\join(p_1,u,p_2)$ combines path $p_1$, singleton $u$ and path $p_2$
     to form a new path.
<li> $\split(u)$ divides the path $p$ containing $u$ at $u$ and returns a pair
     $[p_1, p_2]$ where $p_1$ is the part of $p$ that precedes $u$
     and $p_2$ is the part that follows $u$.
</ul>
Path sets can be implemented using a binary tree to represent each path,
with the infix order of a tree's nodes matching the order of
the path it represents.
The provided implementation extends the
<a href="../trees.html#splayForest"><i>splay forest</i></a>
data structure, which uses the $\splay$ operation
to maintain balance.
This means that $\findpath(u)$ can be done
by performing a splay at node $u$ and returning $u$.
The $\findtail$ operation is done by first finding
the &ldquo;rightmost&rdquo; node in
the tree, then performing a splay at that node.
The $\join$ amd $\split$ operations leverage their counterparts
in the splay forest.
<p>
In order to implement $\addpathcost$ efficiently, in the context of
joins and splits, a <i>differential representation</i> of the
node costs is used. This representation uses two mappings, $\dcost$
and $\dmin$. For each vertex $u$, if $\mincost(u)$ is the minimum cost
for all nodes in $u$'s subtree, then $\dcost(u)=\cost(u) - \mincost(u)$
and $\dmin(u) = \mincost(u)$ if $u$ is a root node and
$\mincost(u) - \mincost(p(u))$ if it is not.
With these definitions,
$\mincost(u)$ can be computed by summing the $\dmin$ fields on the
path from $u$ to the root of its tree and $\cost(u)$ can be computed
by adding $\dcost(u)$ to $\mincost(u)$.
<p>
Using the differential cost representation, the operation
$\addpathcost(u, c)$ can be implemented by adding $c$ to $\dmin(u)$.
The operation $\findpathcost(p)$ can be done by searching the tree,
guided by the $\dmin$ and $\dcost$ values.
Specifically, if the right child $r$ of the current node $u$ has
$\dmin(r)=0$, then the target node is in the right subtree;
if $\dmin(r)\neq 0$, and $\dcost(u)=0$, then $u$ is the target node;
otherwise, the target is in the left subtree.
<p>
The $\join$ and $\split$ operations must update both fields at the root
and its two children.
The rotations used by the splays must also update the $\dmin$ and
$\dcost$ values. An example of this is shown below.
<p>
<div  style="text-align:center;">
<img width="55%" src="figs/updateCosts.png"><br>
</div>
<p>
In general, the costs can be updated using the equations below.
\begin{eqnarray*}
\dcost\,'(u) &=& \dcost(u) + \dmin(u) \\
\dcost\,'(v) &=& \dcost(v) - \dmin'(v) \\
\dmin'(u) &=&\dmin(v) \\
\dmin'(v) &=& \min\{ \dcost(v), \dmin(b)+\dmin(u), \dmin(c)\} \\
\dmin'(a) &=&\dmin(a) + \dmin(u) \\
\dmin'(b) &=&\dmin(b) + \dmin(u) - \dmin'(v) \\ 
\dmin'(c) &=&\dmin(c) - \dmin'(v) 
\end{eqnarray*}
In the fourth equation, the second term is omitted if $b$ is absent
and the third term is omitted if $c$ is absent.
The equations can be easily confirmed by first noting
that $\mincost'(u)=\mincost(v)$,
since the subtree contains the same vertices before and after the rotation.
Similarly, the rotation does not alter the $\mincost$ values
of nodes $a$, $b$ and $c$.
<p>
The core of the provided <i>Javascript</i>implementation is shown below.
<p><textarea id="components" rows="20" cols="80" readonly
          style="font-size: 95%;background-color:lightCyan">
export default class PathSet extends SplayForest {
    #dcost;        // #dcost[u] = cost(u)-mincost(u)
    #dmin;        // #dmin[u] = mincost(u)-mincost(p(u)) 

    constructor(n=10) {
        super(n);
        this.#dcost = new Float32Array(this.n+1).fill(0);
        this.#dmin = new Float32Array(this.n+1).fill(0);
        this.#dcost[0] = this.#dmin[0] = Infinity;
    }

    /** Get/set the dcost of a node. */
    dcost(u, c=-1) {
        if (c != -1) this.#dcost[u] = c;
        return this.#dcost[u];
    }
    
    /** Get/set the dmin of a node.  */
    dmin(u, c=-1) {
        if (c != -1) this.#dmin[u] = c;
        return this.#dmin[u];
    }
    
    /** Get/set the successor of a path. */
    succ(p, s=-1) {
        return super.property(p);
    }
    
    findpath(u, nosplay=false) { return super.find(u,nosplay); }
    
    findtail(q) { return this.splay(super.last(q)); }
    
    addpathcost(q, x) { this.dmin(q, this.dmin(q) + x); }
    
    findpathcost(q) {
        while (true) {
            if (this.right(q) != 0 && this.dmin(this.right(q)) == 0)
                q = this.right(q);
            else if (this.dcost(q) > 0)
                q = this.left(q);
            else
                break;
        }
        q = this.splay(q);
        return [q, this.dmin(q)];
    }
    
    join(r, u, q) {
        let dmin_u = this.dmin(u);
        let sq = (q ? this.property(q) : 0);
        super.join(r,u,q);
        if (r == 0 && q == 0) {
            ; // do nothing
        } else if (r == 0) {
            this.dmin(u, Math.min(this.dmin(u), this.dmin(q)));
            this.dmin(q, this.dmin(q) - this.dmin(u));
        } else if (q == 0) {
            this.dmin(u, Math.min(this.dmin(u), this.dmin(r)));
            this.dmin(r, this.dmin(r) - this.dmin(u));
        } else {
            this.dmin(u, Math.min(this.dmin(r), this.dmin(u), this.dmin(q)));
            this.dmin(r, this.dmin(r) - this.dmin(u));
            this.dmin(q, this.dmin(q) - this.dmin(u));
        }
        this.dcost(u, dmin_u - this.dmin(u)); this.property(u, sq);
        return u;
    }
    
    split(u) {
        let [p,q] = super.split(u);
        let su = this.succ(u);
        if (p != 0) { this.#dmin[p] += this.dmin(u); this.p(p,0); }
        if (q != 0) { this.#dmin[q] += this.dmin(u); this.property(q,su); }
        this.#dmin[u] += this.dcost(u); this.#dcost[u] = 0;
        return [p,q];
    }
    
    rotate(x) {
        let y = this.p(x); if (y <= 0) return;
        let z = this.p(y);
        let a, b, c;
        if (x == this.left(y)) {
            a = this.left(x);  b = this.right(x); c = this.right(y);
        } else {
            a = this.right(x); b = this.left(x);  c = this.left(y); 
        }
        super.rotate(x);
    
        // update dmin, dcost values
        let dmx = this.dmin(x);
        let dma = this.dmin(a); let dmb = this.dmin(b); let dmc = this.dmin(c);
            // note: if a=0, dma = Infinity; same for b,c

        this.dcost(x, this.dcost(x) + dmx);
        this.dmin(x, this.dmin(y));

        this.dmin(y, Math.min(this.dcost(y), dmb+dmx, dmc));
        this.dcost(y, this.dcost(y) - this.dmin(y))

        this.dmin(a, dma + dmx);
        this.dmin(b, dmb + dmx - this.dmin(y));
        this.dmin(c, dmc       - this.dmin(y));
    }
}
</textarea><p>
It's worth noting that the path sets data structure is similar
to the ordered heaps data structure. Indeed, path sets can be
viewed as almost an alternative implementation of ordered heaps,
with the addition of a general $\join$ operation.

<h2>Performance of Dynamic Trees</h2>
The performance of the dynamic trees data structure
is primarily determined by the performance of the underlying
path sets data structure. The dynamic tree operations each
require $O(1)$ path operations, plus one or two exposes.
Each step in an expose requires $O(1)$ path operations per step,
so completing the analysis requires accounting for the number of
steps. For convenience, let's refer to each step as a <i>splice</i>.
<p>
To count the number of splices, note that each splice converts a
dashed edge to a solid edge. This means that the number of splices can
be counted, by counting the number of times a dashed edge
becomes solid. To facilitate the counting of these events,
define an edge from a node $u$ to its parent to be <i>heavy</i>
if the number of nodes in its subtree is more than half the number
in its parents subtree. Note that the number of <i>light</i> edges along any
path from a node to a tree root is at most $\lfloor \lg n \rfloor$.
Consequently, the number of splices in a sequence of $m$ dynamic
tree operations that convert a light dashed edge into a solid edge is
at most $2m \lfloor \lg n \rfloor$.
<p>
If $x$ is the number of splices that convert a heavy dashed edge into
a solid edge, then the total number of splices is
$\leq x + 2m\lfloor \lg n \rfloor$. 
If $y$ is the number of times a heavy solid edge is eliminated
(because it is removed or it becomes dashed or light),
then $x-y\leq n-1$, since there can never more than $n-1$ edges.
Consequently, the number of splices in a sequence of $m$ tree operations
is $\leq y + (n-1) + 2m\lfloor \lg n \rfloor$.
<p>
Since each node has at most one heavy edge connecting it to a child,
an expose converts at most $\lfloor \lg n \rfloor+1$ heavy solid edges
into heavy dashed edges. A cut may convert up to $\lfloor \lg n \rfloor$
heavy solid edges into light solid edges. None of the other tree
operations eliminates any heavy solid edges outside those eliminated
by the expose. Consequently $y\leq 3m\lfloor \lg n \rfloor+1$
and the number of splices is $\leq n+4m\lfloor \lg n \rfloor$
and hence, the total number of path set operations is $O(n +m\log n)$.
If the path set were implemented using balanced binary trees,
the time per path set operation would be $O(\lg n)$, so
the time for a sequence of $m$ dynamic tree operations would be
$O(n\log n+m(\log n)^2)$.
<p>
By implementing the path set using splay trees, this can be improved
to $O(n+m\log n)$.
Showing this requires extending the
analysis of the splay tree data structure to account for the expose
and other other dynamic tree operations.
Before proceeding with that analysis, it's useful to consider two
alternate ways to look at dynamic trees, illustrated below.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/viewpoints.png"><br>
</div>
<p>
The <i>tree of paths</i> viewpoint was used earlier, when describing how
each dynamic tree could be represented as a set of linked paths.
The <i>tree of trees</i> viewpoint, shows each path as a binary
tree, where the infix order of each tree matches
the bottom to top order of the path it represents.
For clarity, each of the trees representing a path is referred
to as a <i>path tree</i>.
<p>
The time required for a sequence of tree operations is dominated
by the time for the splices, and these are dominated by the time
for the path operations, most particularly for the splays that are
performed during those path operations.
As in the original splay tree analysis,
credits are allocated to each path operation and used to pay for
the operation while maintaining enough credits on hand to satisfy the
following credit policy.
<p style="padding-left:5%;">
For each node of $u$, maintain $\rank(u)$ credits, where
$\rank(u)= \lfloor \lg tw(u)\rfloor$ and $tw(u)$ is the sum of
the node weights in the subtree of $u$ within its path tree.
<p>
In the diagram below, nodes in the tree of paths viewpoint are labeled
with their individual weights, while those in the tree of trees are
labeled with their total weights.
<p>
<div  style="text-align:center;">
<img width="50%" src="figs/dtreeWeights.png"><br>
</div>
<p>
Observe that within each path tree, the rank of a node is no larger
than that of its parent. Similarly, the rank of a path tree root
is no larger than the rank of the path tree's successor.
Recall that each splice within an expose includes a $\findpath$ operation,
which involves a splay within one of the path trees.
As an expose progresses up through a sequence of path trees, the ranks
never decrease.
Also, the total weight of a node is never more than $n$,
so its rank is never more than $\lg n$.
<p>
The splay tree lemma (repeated below) can now be applied
using the definition of $\rank$ given above.
<p>
<i>Lemma</i>. Let $u$ be a node in a splay tree with root $v$.
If $3(\rank(v)-\rank(u))+1$ credits are allocated to a splay operation
at $u$, the operation can be fully paid for while continuing to
satisfy the credit policy.
<p>
This implies that the number of credits needed to pay for an expose
while continuing to satisfy the credit policy is at
most $3\lfloor\lg n\rfloor+1$.
The only other tree operation that requires additional credits
to satisfy the credit policy is the $\graft$ operation.
Recall that the operation $\graft(t, u)$ is implemented by
performing expose operations at $t$ and $u$, followed by a join
creating a solid path from $u$ to the tree root, with $u$ as
the root of the path tree representing this path.
To satisfy the credit policy, up to $\lfloor \lg n\rfloor$ additional
credits may be needed, so if $1+\lfloor \lg n\rfloor$
are allocated to each $\graft$, there is one credit to pay for
operation while still satisfying the credit policy.
Since every operation is paid for with allocated credits and the number
of credits allocated to a sequence of $m$ tree operations is $O(n+m\log n)$
the time required for the operations is also $O(n+m\log n)$.

<h2>References</h2>
<dt> [GMG86]
<dd> <i>An $O(E V \log V)$ algorithm for finding a maximal weighted
	matching in general graphs</i> by
	Zvi Galil, Silvio Micali and Harold Gabow.
	In <i>SIAM Journal on Computing</i>, 2/1986.
<dt> [Tarjan87]
<dd> <i>Network Algorithms and Data Structures</i> by Robert E. Tarjan.
     Society for Industrial and Applied Mathematics, 1987.
</dl>
<hr> <h4>&copy; Jonathan Turner - 2022</h4>
<script src="../googleAnalytics.js"></script>
</body>
</html>
