<html>
<head>
<title>Minimum Cost Flows</title>
<link type="text/css" rel="stylesheet" href="../main.css">
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</head>
<body bgcolor=ffffff>
\(
\newcommand{\cost}{\textit{cost}}
\newcommand{\excess}{\textit{excess}}
\newcommand{\lab}{\lambda}
\)

<h1>Minimum Cost Flows<sup>&copy</sup></h1>
The minimum cost flow problem is a generalization of the maximum flow
problem in which each edge $e=(u,v)$ is assigned a real-valued <i>cost</i>
denoted $\cost_e(u,v)$. The cost of a flow $f$
is defined as $\sum_{e=(u,v)} f_e(u,v) cost_e(u,v)$, so edge costs
represent a cost per unit of flow.
A flow is said to be a minimum cost flow, if no other flow with the same
value has a smaller cost.
The objective of the problem is to find a minimum cost flow of maximum value.
Costs are defined to be skew-symmetric,
so $\cost_e(v,u) = -cost_e(u,v)$.
An example of a flow graph with edge costs is shown below.
<p>
<div  style="text-align:center;">
<img width="40%" src="figs/mcflow1.png"><br>
</div>
<p>
Observe that the while the flow shown is a maximum flow,
it is not a minimum cost flow. It can be converted to a
minimum cost flow by adding one unit of flow around the cycle
$(s,a,d,b,s)$. Note that the sum of the edge costs in this cycle
(in the direction indicated) is negative.
This observation is the basis for one approach to finding minimum cost flows.

<h2>Cycle Reduction</h2>
The cycle reduction method [Klein67] can convert any flow into a minimum cost
flow with the same flow value, by repeatedly finding negative cost cycles
with positive residual capacity, then pushing enough flow around the
cycle to saturate one or more edges.
When no negative cycles remain, the flow is a minimum cost flow.
(It's worth noting that a negative cost cycle is not usually a problem for
the min cost flow problem as it is for the shortest path problem;
however, if the graph contains a negative cycle with <i>unbounded capacity</i>,
then there is no minimum cost flow.)
The theorem below provides the required justification for the
cycle reduction method.
<p>
<i>Theorem 1</i>. A flow has minimum cost if an only if there is no
negative cost cycle that is unsaturated.
<p>
<i>Proof</i>.
Clearly if there is a negative cost cycle that is unsaturated,
a lower cost flow of the same value can be obtained by adding flow to the
cycle. It remains to show that a flow that is not minimum must have some
unsaturated negative cost cycle. Let $f$ be a flow
on a graph $G$
that is not minimimum cost and let $f^*$ be a flow with the same value
that has a lower cost. Let $D$ be the graph defined by the edges for
which $f^*-f$ is positive. Now, find a cycle in $D$ (by flow conservation,
there must be one) and add enough flow to the cycle to saturate at least one
of its edges. Repeat until there are no more cycles. At least one of the
cycles identified in this process must have negative cost. $\Box$
<p>
If cycles are chosen arbitrarily, the number of steps
used by the cycle reduction method can be quite large. Indeed, all that can be
said in general is that the number of steps is finite, because the cycle
reduction process maintains integrality of flows and there is a finite number
of integer flows with a given value.
If costs are also integral, the number of steps is at most
$mCU$ where $C$ is the largest cost magnitude and $U$ is the
maximum edge capacity.
The quantity $mCU$ bounds the maximum difference between the largest cost flow
and smallest cost flow. The cycle bound follows from the fact that each cycle
reduces the cost by at least 1. 
Using the Bellman-Moore shortest path algorithm
each cycle-finding step takes $O(mn)$ time,
so the worst-case running time is $O(m^2nCU)$.
Surprisingly, the algorithm can perform reasonably well in practice,
in spite of its very poor worst-case bound.
Several factors account for this.
In practice, the difference between the cost of the initial flow and the 
actual minimium flow cost is much smaller than $mCU$ and each step reduces
the cost by more than 1 (usually much more).
<p>
A <i>Javascript</i> implementation of the cycle reduction method appears
below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
let g;        // shared reference to flow graph
let C;        // C[u] is cost of path to u from source in findCycle
let link;     // link[] is parent edge of u
let q;        // queue used in findCycle
let cycleIds; // array used to label cycles with an integer identifier

export default function mcflowK(fg) {
    g = fg;

    C = new Float32Array(g.n+1);
    link = new Int32Array(g.n+1);
    q = new List(g.n);
    cycleIds = new Int8Array(g.n+1);

    let u = findCycle();
    while (u != 0) {
        let s = augment(u);
        u = findCycle();
    }
}

function findCycle() {
    C.fill(0); link.fill(0); q.clear();
    for (let u = 1; u <= g.n; u++) q.enq(u);

    let last = q.last(); // each pass completes when last removed from q
    while (!q.empty()) {
        let u = q.deq();
        for (let e = g.firstAt(u); e != 0; e = g.nextAt(u,e)) {
            findCycleSteps++;
            if (g.res(e,u) == 0) continue;
            let v = g.mate(u,e);
            if (C[v] > C[u] + g.costFrom(e,u)) {
                link[v] = e;
                C[v] = C[u] +  g.costFrom(e,u);
                if (!q.contains(v)) q.enq(v);
            }
        }

        if (u == last) {
            findCyclePasses++;
            let v = cycleCheck();
            if (v != 0) return v;
            last = q.last();
        }
    }
    return 0;
}

/** Check for a cycle in the link pointers.
 *  @return a vertex on a cycle or 0, if none found
 */
function cycleCheck() {
    cycleIds.fill(0);
    let u = 1; let id = 1;
    while (u <= g.n) {
        // follow parent pointers from u, labeling new vertices
        // seen with the value of id, so we can recognize a loop
        let v = u; let e;
        while (cycleIds[v] == 0) {
            cycleIds[v] = id;
            e = link[v];
            if (e == 0) break;
            v = g.mate(v,e);
        }
        if (cycleIds[v] == id && e != 0) return v;
        
        // find next unlabeled vertex 
        while (u <= g.n && cycleIds[u] != 0) u++;
        id++;
    }
    return 0;
}

/** Add flow to a negative-cost cycle.  */
function augment(z) {
    // determine residual capacity of cycle
    let u = z; let e = link[u]; let f = Infinity;
    do {
        let v = g.mate(u,e);
        f = Math.min(f,g.res(e,v));
        u = v; e = link[u];
    } while (u != z);

    // add flow to saturate cycle
    let ts = '';
    u = z; e = link[u];
    do {
        let v = g.mate(u,e);
        g.addFlow(e,v,f);
        u = v; e = link[u];
    } while (u != z);
    return ts;
}
</textarea> <p>
Notice that the <code>findCycles</code> method checks for cycles
in the parent pointers at the end of every pass. Since the
<code>cycleCheck</code> method is $O(n)$, this does not increase the
worst-case performance beyond $O(mn)$ per cycle found, and short cycles
are typically found long before pass $n$.
The code below can be used to run <code>mcflowK</code> in the web app.
<p>
<pre style="padding-left:5%">
let g = randomFlograph(12,3);
g.randomCapacities(randomInteger, 1, 19);
g.randomCosts(randomInteger, -4, 9);
let [ts] = mcflowK(g,1);
log(ts)
</pre>
<p>
This produces the output below.
<p> <textarea rows="14" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
{
a->[b:5@1 d:21@6 e:14@7]
b[c:12@4 d:15 e:9@5 h:10@-1]
c[b:7@-3 e:16 f:12@8]
d[c:15@6 e:13@8]
e[c:11@3 d:4@8 f:4@-4]
f[c:8@-1 d:10@-1 e:19@7]
g[d:5@9 f:1@4 i:15@-1]
h[i:7@-4 l:21@7]
i[c:2@1 h:5]
j[e:13@5 f:1@1 l:4@1]
k[c:9@1 f:13@-3 g:17@6 i:17@-3 l:18@7]
->l
}

initial cost: 0
cycles with cycle capacity, totalCost
[h:7 i:5 h] 5 -20
[c:16 e:4 f:8 c] 4 -40
[b:10 h:2 i:2 c:7 b] 2 -54

{
a->[b:5@1 d:21@6 e:14@7]
b[c:12@4 d:15 e:9@5 h:10@-1/2]
c[b:7@-3/2 e:16/4 f:12@8]
d[c:15@6 e:13@8]
e[c:11@3 d:4@8 f:4@-4/4]
f[c:8@-1/4 d:10@-1 e:19@7]
g[d:5@9 f:1@4 i:15@-1]
h[i:7@-4/7 l:21@7]
i[c:2@1/2 h:5/5]
j[e:13@5 f:1@1 l:4@1]
k[c:9@1 f:13@-3 g:17@6 i:17@-3 l:18@7]
->l
}
</textarea> <p>
The trace output shows each cycle found, followed by its residual
capacity and the total flow cost after flow is added to the cycle.
In the flow graph, non-zero costs are shown preceded by an @-symbol;
non-zero flows are preceded by a forward slash.
In this example, the initial flow values are all zero.
If a max value flow is computed first,
the final flow is a min cost, max flow.
The following code fragment can be used to observe the performance
experimentally, when computing a min cost, max flow.
<p><pre style="padding-left:5%">
let n=40; let d=4;
let g = randomFlograph(n,d);
g.randomCapacities(randomInteger, 1, 999);
g.randomCosts(randomInteger, -99, 99);

let t = Date.now(); maxflowD(g); let t1 = Date.now() - t;
let c0 = g.totalCost();
t = Date.now(); let [,stats] = mcflowK(g); let t2 = Date.now() - t;
let bound = ~~((c0-g.totalCost())/1000);
let cycles = stats.cycles;
let passes = stats.passes;
let steps = ~~(stats.steps/1000);
log(`n=${g.n} m=${g.m} ${t1}ms bound=${bound}K cycles=${cycles} passes=${passes} ` +
    `steps=${steps}K ${t2}ms`);
</pre><p>
In the sample output appears below, the first three lines show the effect
of doubling the number of edges, while holding the number of vertices constant.
The last three show the effect of doubling the number of vertices while
holding the number of edges constant (approximately).
<p><pre style="padding-left:5%">
n= 40 m=156 1ms bound= 443K cycles= 40 passes= 243 steps=  56K   8ms 
n= 40 m=312 1ms bound=1968K cycles=127 passes= 470 steps= 213K  24ms 
n= 40 m=624 1ms bound=5637K cycles=342 passes= 815 steps= 841K  77ms 
n= 80 m=632 2ms bound=4160K cycles=355 passes=1615 steps=1482K 138ms 
n=160 m=636 2ms bound=2530K cycles=245 passes=1718 steps=1455K 149ms 
</pre><p>
Observe that the initial max flow computation takes a negligible
fraction of the computation time. Also, note that roughly half the edges
in the random graphs have negative costs, so negative cycles are plentiful.
Still, the number of cycles found is consistently smaller than the number
of edges and far smaller than the bound on the number of cycles.
Also, the number of passes in <code>findCycle</code> is generally
no more than about three time the number of edges.
The total number of steps and the running time
appear to increase roughly quadratically with the number of edges and is
fairly insensitive to the number of vertices.
While these are very limited results, they suggest that performance in practice
can be much better than the worst-case analysis suggests.

<h2>Minimum Mean-Cost Cycle Reduction</h2>
Better worst-case bounds can be obtained for the cycle reduction method
if negative cycles are selected with more care.
The <i>mean cost</i> of a cycle is the cycle cost divided by the number of
edges in the cycle. Goldman and Tarjan [GolTar87] show that if the
negative cycle with the smallest (most negative) mean cost is selected,
the number of cycle selection steps is $O(mn \min(\log(nC),m\log n))$
where $C$ is the largest edge cost magnitude. 
Karp [Karp78] proved the following characterization of
the minimum mean cycle cost for any strongly connected digraph with edge costs.
$$
\lambda^* = \min_u \max_{0\leq i < n} \frac{C_i(u) - C_n(u)}{n-i}
$$
where $\lambda^*$ is the minimum mean cycle cost and $C_i(u)$ is the
length of a minimum cost path (not necessarily simple)
from a fixed vertex $s$ to $u$ with exactly $i$ edges
(or $\infty$ if there is no such path).
This can be computed in $O(mn)$ time using the recurrence
$$ C_{i+1}(v) = \min_{(u,v)} \{ C_i(u) + cost(u,v) \} $$
Karp does not give an explicit method for identifying a cycle,
but Chaturvedi and McConnell [ChatMc17] show that if
&ldquo;parent pointers&rdquo; $P_i(u)$ are computed,
along with $C_i(u)$, one can find a cycle by proceeding back along the length
$n$ path defined by the parent pointers from any vertex $u$ that satisfies
the condition in the theorem.
Any cycle on this path is guaranteed to have minimum mean cost.
<p>
A <i>Javascript</i> implementation of the algorithm is shown below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
let g;          // shared reference to flow graph

// data used by findCycle
let C;      // C[i][u]=cost of min cost path (mcp) of length i to u in g
let P;      // P[i][u]=edge to parent of u in mcp of length i to u

export default function mcflowKGT(fg) {
    g = fg;
    C = new Array(); P = new Array();
    for (let i = 0; i <= g.n; i++) {
        C.push(new Float32Array(g.n+1));
        P.push(new Int32Array(g.n+1));
    }

    let [u,i] = findCycle();
    while (u != 0) {
        augment(u,i);
        [u,i] = findCycle();
    }
}

/** Find a negative cost cycle in the residual graph.
 *  @return a pair [u,i] where u is a vertex on a min mean cost cycle and
 *  i is a value for which the path starting at P[i][u] and continuing up
 *  the tree defined by the parent points contains a min mean cost cycle.
 */
function findCycle() {
    let n = g.n;
    // First, compute shortest path lengths of length i <= n
    C[0].fill(0); P[0].fill(0);
    for (let i = 1; i <= n; i++) {
        for (let u = 1; u <= n; u++) {
            // compute C[i][u] the cost of min cost path to u with i edges
            C[i][u] = Infinity; 
            for (let e = g.firstAt(u); e != 0; e = g.nextAt(u,e)) {
                let v = g.mate(u,e);
                if (g.res(e,v) > 0 && C[i-1][v] + g.cost(e,v) < C[i][u]) {
                    C[i][u] = C[i-1][v] + g.cost(e,v); P[i][u] = e;
                }
            }
        }
    }

    // Now apply Karp's equation to find cost of least mean cost cycle
    let meanCost = new Array(n+1);
    let umin = 1;
    for (let u = 1; u <= n; u++) {
        meanCost[u] = [0, (C[n][u] - C[0][u]) / n];
        for (let i = 0; i < n; i++) {
            findCycleSteps++;
            let mc = (C[n][u] - C[i][u]) / (n - i);
            if (mc > meanCost[u][1]) {
                meanCost[u] = [n-i,mc];
            }
        }
        if (meanCost[u][1] < meanCost[umin][1]) umin = u;
    }
    let mmc = meanCost[umin][1];
    if (mmc >= 0) return [0,0];

    // Now follow parent pointers from umin, while checking for cycle
    let mark = new Int32Array(n+1);
    let u = umin; let i = n; mark[u] = i;
    while (i > 0) {
        let e = P[i][u]; let v = g.mate(u,e);
        if (mark[v]) return [v, mark[v]];
        mark[v] = i-1; u = v; i--;
    }
    assert(false, 'findpath: program error');
}

/** Add flow to a negative-cost cycle.
 *  Adds as much flow as possible to the cycle, reducing the cost
 *  without changing the flow value.
 *  @param z is a vertex on a min mean cost cycle
 *  @param i is an integer for which path at length i to z
 *  back up the parent pointers to z is the required cycle
 */
function augment(z,i) {
    // C[i][z] is min mean cycle cost and P values give parent edges
    let u = z; let j = i; let f = Infinity;
    do {
        let e = P[j--][u];
        let v = g.mate(u,e);
        f = Math.min(f,g.res(e,v));
        u = v;
    } while (u != z);

    // now add flow to the path to saturate cycle
    u = z; j = i;
    do {
        let e = P[j--][u];
        let v = g.mate(u,e);
        g.addFlow(e,v,f);
        u = v;
    } while (u != z);
}
</textarea> <p>
While this version does use fewer cycles than the basic version of Klein's
method, the improvement is fairly modest on random graphs, and the time required
to find each cycle is much larger, making it slower than the basic version,
at least for this class of graphs.
The following code can be used to demonstrate this.

<p><pre style="padding-left:5%">
let n=40; let d=4;
let g = randomFlograph(n,d);
g.randomCapacities(randomInteger, 1, 999);
g.randomCosts(randomInteger, -99, 99);

let t = Date.now(); maxflowD(g); let t1 = Date.now() - t;
let c0 = g.totalCost();
t = Date.now(); let [,stats] = mcflowKGT(g); let t2 = Date.now() - t;
let bound = ~~((c0-g.totalCost())/1000);
let cycles = stats.cycleCount;
let steps = ~~(stats.findCycleSteps/1000);
log(`n=${g.n} m=${g.m} bound=${bound}K cycles=${cycles} ` +
    `steps=${steps}K ${t1}ms ${t2}ms`);
</pre><p>
Sample results appear below.
<p><pre style="padding-left:5%">
n= 40 m=156 2ms bound= 335K cycles= 33 steps=  479K   59ms 
n= 40 m=312 1ms bound=2132K cycles=108 steps= 2896K  270ms 
n= 40 m=624 2ms bound=5498K cycles=231 steps=11955K 1058ms 
n= 80 m=632 3ms bound=4278K cycles=202 steps=21830K 1908ms 
n=160 m=636 1ms bound=1150K cycles= 99 steps=22914K 1973ms 
</pre><p>
Comparing these to the results from the last section,
the new algorithm does require fewer negative cycles
but for random graphs, the difference is not nearly enough
to offset the extra time spent finding the cycles.

<h2>Min Cost Augmenting Path</h2>

If the current flow in a flow graph has minimum cost, then adding flow
to an augmenting path $P$ of minimum cost produces another minimum cost flow.
To understand why, suppose that the new flow is not minimum cost.
In that case, it has a negative cycle that is unsaturated. Since the original flow did
not have a negative cycle, the path augmentation must have caused some
previously saturated edges to become unsaturated,
and these must be reversals of edges on $P$. Let's start with a
simple case where a single edge $e=(u,v)$ appears on $P$
and its reversal $(v,u)$ appears on $C$. Let $H$ be the graph
consisting of $P$ together with $C$. Since $C$ is a negative cost
cycle, the cost of $H$ is less than the cost of $P$.
If $(u,v)$ and $(v,u)$ are both removed from $H$, the resulting
graph has the same cost as $H$ (by skew symmetry of edge costs).
This graph forms an augmenting path from $s$ to $t$ and has a lower
cost than $P$, contradicting the fact that $P$ is a minimum cost
augmenting path.
<p>
The general case is handled in a similar way. Again, let $H$ be the
graph obtained by combining $P$ and $C$. Observe that this graph
is Eulerian. That is, every vertex but $s$ and $t$ has the same
number of incoming edges as outgoing edges, while $s$ has one
extra outgoing edge and $t$ has one extra incoming edge.
Because the graph is Eulerian, it can be decomposed into a single
$s$-$t$ path and 0 or more cycles. Moreover, the graph obtained
by removing all matched pairs $(u,v)$ on $P$ and $(v,u)$ on $C$ is also Eulerian
and has the same cost as $H$. Since the cycles in this graph consist
of edges that were unsaturated in the original flow graph,
they are non-negative, so the remaining path is an augmenting
path with lower cost than $P$,
again yielding a contradiction. This argument yields the following theorem
<p>
<i>Theorem 2</i>. Given a flow graph with a minimum cost flow,
adding flow to a minimum cost augmenting path yields another
minumum cost flow.
<p>
This theorem is the basis for the minimum cost augmenting path algorithm,
which can be applied to any flow graph in which there are no negative cost
cycles. With integer edge capacities, each augmenting path step increases
the flow by at least 1, so the number of steps is bounded by the maximum flow value.
If the Bellman-Moore algorithm is used to find the least-cost augmenting path,
the running time is $O(mnP)$ where $P$ is the number of paths that
must be found to reach a maximum flow; it is bounded by the maximum flow value,
but is typically much smaller.
<p>
In a graph that does have negative cost cycles, the negative cycles must
be eliminated before minimum cost augmentation can be applied.
One way to do this is using one of the cycle reduction algorithms discussed earlier.
An alternative approach involves modifying the algorithm to work with
<i>preflows</i> instead of flows. Recall that a preflow is similar to a flow in that
it respects the capacity constraints, but differs by allowing the flow balance
condition to be violated. That is, the flow entering a (non-source/sink) vertex
need not be balanced by the the flow leaving.
The <i>excess flow</i> at a vertex is defined to be the difference between
the flow entering and the flow leaving, and may be either positive or negative.
<p>
Preflows can be used to eliminate negative cycles by simply saturating
every edge with negative cost, at the start of the algorithm. This gives us
a preflow in which some vertices have positive excess and some have negative.
Those in the first group are called <i>sources</i> while those in the second
group are called <i>sinks</i>.
From this initial state, a minimum cost flow can be found by repeatedly pushing
flow along a shortest path from any source to any sink, stopping when
the excesses are all zero. At this point, all unsaturated negative cycles
have been eliminated.
<p>
Once the negative cycles have been eliminated, a maximum flow can be found
by computing least-cost augmenting paths from the original source vertex to
the original sink. Alternatively, one can combine the two steps, by treating
the original source and sink just like the sources/sinks that are created when the
negative cost edges are saturated. One does this, by assigning an excess
to the original source equal to its max flow value. The original sink is assigned a
negative excess of the same magnitude.
The running time is $O(mnP)$, assuming Bellman-Ford is used for the shortest
path computations and $P$ is the number of paths. $P$ is bounded by the sum of
the positive excesses at the start of the algorithm, which is bounded
by the maximum flow value plus the sum of the capacities of the negative cost edges.
<p>
This algorithm was first described in [Jewell1958].
A <i>Javascript</i> implementation appears below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
let g;        // shared reference to flow graph
let link;     // link[u] is parent edge of u
let excess;   // excess[u] is excess flow entering u
let sources;  // list of sources (nodes with positive excess)
let sinks;    // list of sinks (nodes with negative excess)

export default function mcflowJ(fg) {
    g = fg;

    link = new Int32Array(g.n+1);
    excess = new Int32Array(g.n+1);
    sources = new List(g.n); sources.addPrev(); // doubly linked
    sinks = new List(g.n); sinks.addPrev();

    // Determine a max flow so that we can initialize excess
    // values at s and t
    maxflowD(g);
    excess[g.source] = g.totalFlow();
    excess[g.sink] = -g.totalFlow();
    let totalExcess = excess[g.source];
    g.clearFlow();

    // saturate negative cost edges
    for (let e = g.first(); e != 0; e = g.next(e)) {
        if (g.cost(e) < 0) {
            g.flow(e, g.cap(e));
            excess[g.tail(e)] -= g.cap(e);
            excess[g.head(e)] += g.cap(e);
            totalExcess += g.cap(e);
        }
    }
    for (let u = 1; u <= g.n; u++) {
        if (excess[u] > 0) {
            sources.enq(u);
        } else if (excess[u] < 0) {
            sinks.enq(u);
        }
    }

    let t = findpath();
    while (t) {
        augment(t);
        t = findpath();
    }
}

function findpath() {
    let c = new Float32Array(g.n+1);
    let q = new List(g.n);
    link.fill(0); c.fill(Infinity);

    // search from all sources in parallel
    for (let s = sources.first(); s != 0; s = sources.next(s)) {
        c[s] = 0; q.enq(s);
    }
    let t = 0; let cmax = -Infinity;
    while (!q.empty()) {
        let u = q.deq();
        if (sinks.contains(u)) t = u;
        for (let e = g.firstAt(u); e; e = g.nextAt(u,e)) {
            if (g.res(e,u) == 0) continue;
            let v = g.mate(u,e);
            if (c[v] > c[u] + g.costFrom(e,u)) {
                c[v] = c[u] + g.costFrom(e,u); link[v] = e;
                if (!q.contains(v)) q.enq(v);
            }
        }
    }
    return t;
}

function augment(t) {
    let u = t; let delta = Infinity;
    for (let e = link[u]; e != 0; e = link[u]) {
        u = g.mate(u,e);
        delta = Math.min(delta, g.res(e,u));
    }
    delta = Math.min(delta, excess[u]);
    delta = Math.min(delta, -excess[t]);

    u = t; let ts = ''; let cost = 0;
    for (let e = link[u]; e; e = link[u]) {
        u = g.mate(u,e); g.addFlow(e,u,delta);
    }
    excess[u] -= delta; excess[t] += delta;
    if (excess[u] == 0) sources.delete(u);
    if (excess[t] == 0) sinks.delete(t);
}
</textarea> <p>
Observe that in this implementation, the <code>findpath</code> function
searchs from all sources at the same time (you can think of it as computing
a shortest path tree from a pseudo-source with a zero cost edge to every
vertex).
The following code can be used to demonstrate the algorithm.
<p><pre style="padding-left:5%">
let g = randomFlograph(12,3);
g.randomCapacities(randomInteger, 1, 19);
g.randomCosts(randomInteger, -3, 9);
let [ts] = mcflowJ(g,1);
log(ts)
</pre><p>
Sample output appears below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
{
a->[b:6@5 d:12@-2/12 e:18@1]
b[c:19 e:11@-3/11]
c[b:5@9 d:6@3 f:3@-3/3]
d[b:1@5 c:8@-2/8 e:17@9 f:6@2]
e[b:5@4 c:15@9 g:13@-3/13]
f[b:4@9 c:11@-2/11 d:7@-2/7]
g[d:1@1 k:9@4 l:14@-2/14]
h[l:18@2]
i[c:1@4 d:5@1 f:18@-2/18 g:4@8]
j[d:4@6 l:4@3]
k[b:1@8 c:11@8 d:4@7 f:16@6 h:16@1]
->l
}

sources, sinks and paths with added flow and resulting flow cost
[a:1 c:16 d:11 f:3 l:1] [b:-11 e:-2 g:-1 i:-18]
  [a:18 e:11 b] 1 -217
[c:16 d:11 f:3 l:1] [b:-10 e:-2 g:-1 i:-18]
  [l:14 g] 1 -215
[c:16 d:11 f:3] [b:-10 e:-2 i:-18]
  [f:18 i] 3 -209
[c:16 d:11] [b:-10 e:-2 i:-15]
  [c:11 f:15 i] 11 -165
[c:5 d:11] [b:-10 e:-2 i:-4]
  [d:7 f:4 i] 4 -149
[c:5 d:7] [b:-10 e:-2]
  [d:1 b:1 e] 1 -147
[c:5 d:6] [b:-10 e:-1]
  [d:12 a:17 e:11 b] 6 -111
[c:5] [b:-4 e:-1]
  [c:8 d:6 a:11 e:5 b] 4 -79
[c:1] [e:-1]
  [c:4 d:2 a:7 e] 1 -74

{
a->[b:6@5 d:12@-2/1 e:18@1/12]
b[c:19 e:11@-3/1]
c[b:5@9 d:6@3 f:3@-3/3]
d[b:1@5/1 c:8@-2/3 e:17@9 f:6@2]
e[b:5@4 c:15@9 g:13@-3/13]
f[b:4@9 c:11@-2 d:7@-2/3]
g[d:1@1 k:9@4 l:14@-2/13]
h[l:18@2]
i[c:1@4 d:5@1 f:18@-2 g:4@8]
j[d:4@6 l:4@3]
k[b:1@8 c:11@8 d:4@7 f:16@6 h:16@1]
->l
}
</textarea> <p>
The trace output starts with the graph showing the initial preflow.
For each path search, it shows the sources and sinks at the start
of the search (including their excess values), plus the
selected augmenting path with its residual capacities, the flow
added to the path and the flow cost immediately following the augmentation.
Note that the amount of flow added is limited by the excess
at the source and sink, in addition the path capacity.
<p>
The following code can be used to evaluate the performance of the algorithm.
<p><pre style="padding-left:5%">
let n=160; let d=4;
let g = randomFlograph(n,d);
g.randomCapacities(randomInteger, 1, 999);
g.randomCosts(randomInteger, -99, 99);

let bound = 0;
for (let e = g.first(); e; e = g.next(e))
    if (g.cost(e) < 0) bound += g.cap(e);

let t = Date.now(); let [,stats] = mcflowJ(g); t = Date.now() - t;
bound = ~~((bound + g.totalFlow())/1000);
let paths = stats.paths;
let steps = ~~(stats.steps/1000);
log(`n=${g.n} m=${g.m} flow=${g.totalFlow()} bound=${bound}K paths=${paths} ` +
    `steps=${steps}K ${t}ms`);
</pre><p>
Note that the bound in this case is the sum of the maximum flow value
and the total capacity of the negative edges, and is largely determined
by the negative capacity.
<p><pre style="padding-left:5%">
n= 40 m=156 flow=  286 bound= 37K paths=106 steps= 21K  7ms 
n= 40 m=312 flow= 4818 bound=115K paths=216 steps= 88K 20ms 
n= 40 m=624 flow=19086 bound=244K paths=367 steps=318K 54ms 
n= 80 m=632 flow= 5384 bound=196K paths=477 steps=468K 79ms 
n=160 m=636 flow=  183 bound=163K paths=531 steps=486K 89ms 
</pre><p>
The number of paths is far smaller than
the bound; the number of steps and run time appear to
grow roughly in proportion to the product of $m$ and the number of paths.
<p>
Since Jewell's algorithm starts by saturating all the negative cost edges,
the initial preflow has no unsaturated negative cost edges.
This property can be maintained throughout the algorithm using
the edge cost transformation of Edmonds and Karp,
previously used for applying Dijkstra's algorithm
to the all pairs shortest path problem.
In this case, the edge cost transformation must be adjusted
after each augmenting path step. To facilitate this adjustment, it's
helpful to look at the edge cost transformation in a more general way.
For each vertes $u$ in a flow graph, let $\lab(u)$ be a numeric label.
Any such labeling can be used to define an alternate edge cost function.
$$
cost_{\lab}(u,v) = cost(u,v) + \lab(u) - \lab(v)
$$
Note that this cost function shifts the cost of a $u$-$v$ path by
$\lab(u) - \lab(v)$, so a path $p$ from $u$ to $v$ is
a shortest path with respect to $\cost_\lab$ if and only if it
is a shortest path with respect to the original costs.
Thus, shortest paths can be computed based on any such labeling.
If $\cost_\lab(u,v) \geq 0$ for all edges $(u,v)$, one can compute
shortest paths using Dijkstra's algorithm or any other shortest path
algorithm that requires non-negative edge lengths/costs.
If the vertex labels are all shortest path distances from some source
vertex $s$, then $\cost_\lab(u,v) \geq 0$ is guaranteed by the
<a href="./shortPaths.html#sptTheorem">shortest path tree</a> theorem.
Moreover, any edge $(u,v)$ in a shortest path tree rooted at $s$ has
$\cost_\lab(u,v)=0$.
<p>
In the context of the min cost flow problem, a vertex labeling is said
to be <i>valid</i> with respect to a flow $f$ if
$\cost_\lab(u,v)\geq 0$ for all edges $e=(u,v)$ with $res_e(u,v)>0$.
Given a valid labeling, a minimum cost augmenting path can be computed
using Dijkstra's algorithm. Let $c(u)$ be the cost of the path from $s$ to $u$.
Before flow is added to the augmenting path
$\cost_\lab(u,v) + c(u) - c(v)\geq 0$
for all edges $e=(u,v)$ with positive residual capacity,
by the shortest path tree theorem and for edges on a shortest path
$\cost_\lab(u,v) + c(u) - c(v)=0$. After flow is added to the augmenting
path, the only new edges are reverse path edges.
Consequently, after flow is added, all unsaturated edges $(u,v)$ satisfy
$$
cost_\lab(u,v) + c(u) - c(v) \geq 0
$$
or equivalently
$$
cost(u,v) + (\lab(u) + c(u)) - (\lab(v) + c(v)) \geq 0
$$
Thus, one can maintain the validity of the labeling, by adding $c(u)$ to the
current label for all vertices $u$.
Now this works if all vertices are reachable from a source vertex,
but what if some are not? For these unreachable vertices, it suffices to
add to their labels a value that is at least as large as the largest finite path cost.
<p>
In Jewell's algorithm, the initial labels can be set to zero, since the
initial preflow has no unsaturated negative edges.
From that point on, it can compute shortest paths
using Dijkstra's algorithm (or any algorithm that
requires non-negative edge lengths), updating
the labels after each step as described above.
This yields a running time of
$O(S(m,n)P)$, where $S(m,n)$ is the time required for the shortest path
computation and is determined by the choice of algorithm and data structure;
$P$ is the number of paths.
As before $P$ is bounded by the sum of the maximum flow value and the
total capacity of the negative cost edges.
<p>
A <i>Javascript</i> implementation of this version of Jewell's algorithm
(referred to here as the JEK algorithm, for Jewell, Edmonds and Karp)
appears below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
let g;        // shared reference to flow graph
let link;     // link[u] is parent edge of u
let lambda;   // lambda[u] is vertex label used to make costs non-negative
let excess;   // excess[u] is excess flow entering u
let sources;  // list of sources (nodes with positive excess)
let sinks;    // list of sinks (nodes with negative excess)

let border;   // heap used by findpath
let c;        // array of path costs used by findpath

/** Find minimum cost maximum flow in a weighted flow graph using Orlin's
 *  capacity scaling algorithm.
 *  Requires that the original graph has no negative cost cycles.
 */
export default function mcflowJEK(fg) {
    g = fg;

    link = new Int32Array(g.n+1);
    lambda = new Float32Array(g.n+1);
    excess = new Int32Array(g.n+1);
    sources = new List(g.n); sources.addPrev(); // doubly linked
    sinks = new List(g.n); sinks.addPrev();
    border = new ArrayHeap(g.n,2);
    c = new Float32Array(g.n+1);

    // Determine a max flow so that we can initialize excess
    // values at s and t
    maxflowD(g);
    excess[g.source] = g.totalFlow();
    excess[g.sink] = -g.totalFlow();
    g.clearFlow();

    // saturate negative cost edges
    for (let e = g.first(); e != 0; e = g.next(e)) {
        if (g.cost(e) < 0) {
            g.flow(e, g.cap(e));
            excess[g.tail(e)] -= g.cap(e);
            excess[g.head(e)] += g.cap(e);
        }
    }
    sources.clear(); sinks.clear();
    for (let u = 1; u <= g.n; u++) {
        if (excess[u] > 0) {
            sources.enq(u);
        } else if (excess[u] < 0) {
            sinks.enq(u);
        }
    }

    let t = findpath();
    while (t) {
        augment(t); t = findpath();
    }
}

/** Find a least cost augmenting path from some source and update the labels.
 *  @return the "sink" vertex for the computed path; on return, the link
 *  vector defines the path from the sink back to some source
 */
function findpath() {
    border.clear(); link.fill(0); c.fill(Infinity);

    // search from all sources in parallel
    for (let s = sources.first(); s != 0; s = sources.next(s)) {
        c[s] = 0; border.insert(s,0); steps++;
    }
    let t = 0; let cmax = -Infinity;
    while (!border.empty()) {
        let u = border.deletemin();
        cmax = Math.max(cmax,c[u]);
        if (sinks.contains(u)) t = u;
            // don't stop yet as need all c values to update lambda
        for (let e = g.firstAt(u); e != 0; e = g.nextAt(u,e)) {
            if (g.res(e,u) == 0) continue;
            let v = g.mate(u,e);
            if (c[v] > c[u] + g.costFrom(e,u) + (lambda[u]-lambda[v])) {
                link[v] = e;
                c[v] = c[u] + g.costFrom(e,u) + (lambda[u]-lambda[v]);
                if (!border.contains(v)) border.insert(v,c[v]);
                else border.changekey(v,c[v]);
            }
        }
    }
    if (t != 0) { // adjust labels
        for (let u = 1; u <= g.n; u++) {
            lambda[u] += Math.min(c[u],cmax);
        }
    }
    return t;
}

/** Augment the flow along a path
 *  @param t is the sink vertex for the path; the path is defined
 *  by the link array
 */
function augment(t) {
    let u = t; let delta = Infinity;
    for (let e = link[u]; e != 0; e = link[u]) {
        u = g.mate(u,e);
        delta = Math.min(delta, g.res(e,u));
    }
    delta = Math.min(delta, excess[u]);
    delta = Math.min(delta, -excess[t]);

    u = t; let ts = ''; let cost = 0;
    for (let e = link[u]; e != 0; e = link[u]) {
        u = g.mate(u,e);
        g.addFlow(e,u,delta);
    }
    excess[u] -= delta; excess[t] += delta;
    if (excess[u] == 0) sources.delete(u);
    if (excess[t] == 0) sinks.delete(t);
}
</textarea> <p>
The code used to evaluate the performance of the
the original version of Jewell's algorithm can
be trivially modified for this version.
Here is some sample data.
<p><pre style="padding-left:5%">
n= 40 m=156 flow=  418 bound= 29K paths= 96 steps=  51K  6ms 
n= 40 m=312 flow= 6311 bound=118K paths=232 steps= 228K 20ms 
n= 40 m=624 flow=19963 bound=219K paths=366 steps= 606K 46ms 
n= 80 m=632 flow= 4886 bound=193K paths=503 steps=1092K 66ms 
n=160 m=636 flow= 1214 bound=162K paths=565 steps=1695K 86ms 
</pre><p>
For random graphs the performance is very similar to the original version.

<h2>Orlin's Scaling Algorithm</h2>

Because the worst-case time required for Jewell's algorithm's grows
in proportion with the edge capacities, it is not considered a polynomial
time algorithm.
Orlin's scaling algorithm [AhMaOr93] can be viewed as a generalization of
Jewell's algorithm, which does run in polynomial time.
It uses a scale factor $\Delta$,
and limits augmenting paths to those edges with a residual capacity
$\geq \Delta$ (referred to as <i>eligible</i> edges).
Once all augmenting paths for a particular value of $\Delta$ are found,
$\Delta$ is halved and the augmenting path searches are resumed using
the newly eligible edges, in addition to those that remain eligible from
the previous phase.
This allows it to avoid augmenting path steps that make only a small improvement
in the flow.
If the period between successive changes to $\Delta$ is called a <i>phase</i>,
the number of augmenting path steps per phase
is $O(m)$ (this is justified below), and if $U$ is the maximum edge capacity,
the number of phases is at most $\lceil \log_2 U \rceil$.
Conseqently, the total number of augmenting path steps is
$O(m \log U)$ and the running time is $O(S(m,n) m \log U)$ where again $S(m,n)$
is the time for the shortest path computation.
<p>
Within each phase, the vertex labels $\lab(u)$ can be maintained
as was discussed in the last section.
However, at the end of a phase, the reduction in $\Delta$
makes more edges eligible, potentially making
$\cost_\lab$ negative for some eligible edges.
This is addressed by adding $\Delta$ units of flow to each
edge for which $\cost_\lab$ is negative, possibly creating
new sources and sinks.
<p>
The algorithm can be stated as follows.
Initialize $\lab(u)=0$ for all $u$,
$\excess(s) = F$ (where $F$ is the value of a maximum flow),
$\excess(t)=-F$
and $\excess(u)=0$ for all other vertices $u$.
Let $\Delta$ be the largest power of 2 that is $\leq U$.
Now, repeat the following step so long as $\Delta\geq 1$.
<p style="padding-left:5%">
For each edge $(u,v)$ with $\cost_\lab (u,v)<0$ and $res(u,v)\geq \Delta$,
add $\Delta$ units of flow from $u$ to $v$, add $\Delta$ to $\excess(v)$
and subtract $\Delta$ from $\excess(u)$.
<p style="padding-left:5%">
While there is a path with residual capacity $\geq \Delta$ from a vertex $\sigma$
with $\excess(\sigma)\geq \Delta$ to a vertex
$\tau$ with $\excess(\tau)\leq -\Delta$,
add $\Delta$ units of flow to the path, subtract $\Delta$ from $\excess(\sigma)$
and add $\Delta$ to $\excess(\tau)$; 
also, for each vertex $u$, add $\min\{c(u),c_{max}\}$ to $\lab(u)$
where $c(u)$ is the minimum
path cost from $\sigma$ to $u$ using eligible edges
and $c_{max}$ is the largest finite value of $c(u)$.
<p style="padding-left:5%">
When no augmenting paths remain, divide $\Delta$ by 2.
<p>
Note that when a phase ends, either no vertex has positive excess $\gt\Delta$
or no vertex has negative excess $\lt\Delta$. Until this condition holds, there must
be an augmenting path with residual capacity $\gt\Delta$.
At the start of each phase, the total positive excess is $\lt 2n\Delta$.
Initially, this is true because the maximum flow value is $\leq nU$.
At the start of a new phase with scaling factor $\Delta$,
every vertex has a positive excess $\lt 2\Delta$ or every vertex has
a negative excess $\gt 2\Delta$.
In either case, the total positive excess is $\lt 2n\Delta$.
<p>
In the first step of a phase, newly eligible edges increase the total positive
excess by at most $m\Delta$, so the total positive excess is $\lt (2n+m)\Delta$
after the first step. Since each augmenting path reduces the positive excess of
some source by $\Delta$, there are at most $2n+m$ augmenting path steps per phase.
This justifies the earlier statement that the number of path searches per phase
is $O(m)$.
<p>
A <i>Javascript</i> version of Orlin's algorithm appears below.
<p> <textarea rows="20" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
let g;        // shared reference to flow graph
let Delta;    // scaling parameter
let link;     // link[u] is parent edge of u
let lambda;   // lambda[u] is vertex label used to make costs non-negative
let excess;   // excess[u] is excess flow entering u
let sources;  // list of sources (nodes with positive excess)
let sinks;    // list of sinks (nodes with negative excess)
export default function mcflowO(fg) {
    g = fg;

    link = new Int32Array(g.n+1);
    lambda = new Float32Array(g.n+1);
    excess = new Int32Array(g.n+1);
    sources = new List(g.n); sources.addPrev(); // doubly linked
    sinks = new List(g.n); sinks.addPrev();

    // Initialize scaling factor
    let maxcap = 0;
    for (let e = g.first(); e != 0; e = g.next(e)) {
        maxcap = Math.max(maxcap, g.cap(e,));
    }
    for (Delta = 1; 2*Delta <= maxcap; Delta <<= 1) {}

    // Determine a max flow so that we can initialize excess
    // values at s and t
    maxflowD(g);
    excess[g.source] = g.totalFlow();
    excess[g.sink] = -g.totalFlow();
    g.clearFlow();

    while (Delta >= 1) {
        newPhase();
        let t = findpath();
        while (t) {
            augment(t); t = findpath();
        }
        Delta /= 2;
        if (trace) traceString += '\n';
    }
    if (trace) traceString += g.toString(1);
    return [traceString, {  'phases': phases, 'paths': paths,
                               'steps': steps } ];
}

function newPhase() {
    // If any edge violates labeling condition, add Delta units of
    // flow to it. This eliminates it from the residual graph for
    // the current scaling factor.
    let s = ''; let flow = 0; let cost = 0;
    for (let e = g.first(); e != 0; e = g.next(e)) {
        let u = g.tail(e); let v = g.head(e);
        if (g.res(e,u) >= Delta) {
            if (g.costFrom(e,u) + (lambda[u] - lambda[v]) < 0) {
                g.addFlow(e,u,Delta);
                excess[u] -= Delta; excess[v] += Delta;
            }
        }
        if (g.res(e,v) >= Delta) {
            if (g.costFrom(e,v) + (lambda[v] - lambda[u]) < 0) {
                g.addFlow(e,v,Delta);
                excess[v] -= Delta; excess[u] += Delta;
            }
        }
    }

    // identify candidate sources and sinks
    sources.clear(); sinks.clear();
    for (let u = 1; u <= g.n; u++) {
        steps++;
        if (excess[u] >= Delta) {
            sources.enq(u);
        } else if (excess[u] <= -Delta) {
            sinks.enq(u);
        }
    }
    return;
}

/** Find a least cost augmenting path from some source and update the labels.
 *  @return the "sink" vertex for the computed path; on return, the link
 *  vector defines the path from the sink back to some source
 */
function findpath() {
    let c = new Float32Array(g.n+1);
    let border = new ArrayHeap(g.n,2);
    link.fill(0); c.fill(Infinity);

    // search from all sources in parallel
    for (let s = sources.first(); s != 0; s = sources.next(s)) {
        c[s] = 0; border.insert(s,0); steps++;
    }
    let t = 0;
    let cmax = -Infinity;
    while (!border.empty()) {
        let u = border.deletemin();
        cmax = Math.max(cmax,c[u]);
        if (t == 0 && sinks.contains(u)) t = u;
            // don't stop yet as need all c values to update lambda
        for (let e = g.firstAt(u); e != 0; e = g.nextAt(u,e)) {
            steps++;
            if (g.res(e,u) < Delta) continue;
            let v = g.mate(u,e);
            if (c[v] > c[u] + g.costFrom(e,u) + (lambda[u]-lambda[v])) {
                link[v] = e;
                c[v] = c[u] + g.costFrom(e,u) + (lambda[u]-lambda[v]);
                if (!border.contains(v)) border.insert(v,c[v]);
                else border.changekey(v,c[v]);
            }
        }
    }
    if (t != 0) { // adjust labels
        for (let u = 1; u <= g.n; u++) {
            lambda[u] += Math.min(c[u],cmax);
        }
        steps += g.n;
    }
    return t;
}

/** Augment the flow along a path
 *  @param t is the sink vertex for the path; the path is defined
 *  by the link array
 */
function augment(t) {
    let u = t; let ts = '';
    if (trace) ts += g.x2s(t);
    for (let e = link[u]; e != 0; e = link[u]) {
        steps++;
        u = g.mate(u,e);
        if (trace) {
            ts = `${g.x2s(u)}:${g.res(e,u)} ${ts}`;
        }
        g.addFlow(e,u,Delta);
    }
    if (trace) {
        traceString += sources.toString(u => g.x2s(u) + ':' + excess[u]) + ' ';
        traceString += sinks.toString(u => g.x2s(u) + ':' + excess[u]) + '\n  ';
        traceString += `[${ts}] ${Delta} ${g.totalCost()}\n`;
    }
    excess[u] -= Delta; excess[t] += Delta;
    if (excess[u] < Delta) sources.delete(u);
    if (excess[t] > -Delta) sinks.delete(t);
}
</textarea> <p>
Some sample output from a demonstration run appears below.
<p> <textarea rows="14" cols="80" readonly
        style="font-size: 95%;background-color:lightCyan">
sources, sinks and paths with added flow and resulting flow cost
[b:8 e:8 l:8] [a:-8 h:-8 j:-8]
  [b:8 a] 8 -32
[e:8 l:8] [h:-8 j:-8]
  [e:8 h] 8 -16
[l:8] [j:-8]
  [l:8 j] 8 0

[c:8 d:4 f:4] [e:-12 i:-4]
  [f:4 e] 4 8
[c:8 d:4] [e:-8 i:-4]
  [c:4 i] 4 8
[c:4 d:4] [e:-8]
  [d:4 e] 4 -8
[c:4] [e:-4]
  [c:4 e] 4 0

[d:2] [f:-2]
  [d:3 f] 2 -6

[d:1] [f:-1]
  [d:1 f] 1 -9

{
a->[b:9@-2 c:10@7 d:1@7]
b[f:8]
c[b:4@-3 e:4@2 f:1@2]
d[b:9@9 e:9@9 f:3@-2/3]
e[b:7@9 c:6@-2 d:6@4 f:7@-1 i:9@7]
f[b:1@5 c:2@6 d:3@-1/3]
g[b:4@-2 e:8@1 j:5@9 l:9@3]
h[c:2@5 d:3@-1 e:9@-2 f:5@6 g:9@7]
i[b:1@1 c:6]
j[c:1@4 i:8 l:12@-2]
k[l:5@9]
->l
}
</textarea> <p>
The trace output is similar to that shown for Jewell's algorithm.
The only real difference is the blank lines separating the phases.
Some sample performance data appears below.
<p><pre style="padding-left:5%">
n= 40 m=156 phases=12 paths=131 steps= 45K  8ms
n= 40 m=312 phases=13 paths=255 steps=172K 24ms 
n= 40 m=624 phases=14 paths=527 steps=650K 62ms 
n= 80 m=632 phases=13 paths=486 steps=647K 66ms 
n=160 m=636 phases=12 paths=432 steps=561K 62ms 
</pre><p>
For these random graphs, the number of path searches is actually larger
than for Jewell's algorithm, but it can be expected to perform better in
the worst-case.

<h2>References</h2>
<dl>
<dt> [AhMaOr93]
<dd> <i>Network Flows, Theory, Algorithms and Applications</i>
     by R. K Ahuja, T. L. Magnanti and J. B. Orlin.
     Prentice Hall, 1993.
<dt> [ChatMc17]
<dd> &ldquo;A note on finding minimum mean cycles&rdquo; by
     Mmanu Chaturvedi and Ross M. McConnell. In
     <i>Information Processing Letters</i> 11/2017.
<dt> [GolTar87]
<dd> &ldquo;Finding Minimum-Cost Circulations by Cancelling
     Negative Cycles,&rdquo; by A. V. Goldberg and R. E. Tarjan. In
     <i>Proceedings of the ACM Symposiumm on Theoretical Computer Science</i>,
     1988.
<dt> [Karp78]
<dd> &ldquo;A characterization of the minimum cycle mean in a diagraph,&rdquo;
     by R. Karp. In <i>Discrete Mathematics</i>, 1978.
<dt> [Klein67]
<dd> &ldquo;A primal method for minimal cost flows.&rdquo;
     <i>Management Science</i>, 1967.
<dt> [Tarjan87]
<dd> <i>Network Algorithms and Data Structures</i> by Robert E. Tarjan.
     Society for Industrial and Applied Mathematics, 1987.
</dl>
<hr> <h4>&copy; Jonathan Turner - 2022</h4>
<script src="../googleAnalytics.js"></script>
</body>
</html>
